{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()で可視化されない人はこのセルを実行してください。\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "Hyn-OCmZgbf",
    "id": "chapter_name"
   },
   "source": [
    "#  教師あり学習（回帰）の応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[2.1 モデルの汎化](#2.1-モデルの汎化)**\n",
    "    - **[2.1.1 汎化とは](#2.1.1-汎化とは)**\n",
    "    - **[2.1.2 正則化](#2.1.2-正則化)**\n",
    "    - **[2.1.3 ラッソ回帰](#2.1.3-ラッソ回帰)**\n",
    "    - **[2.1.4 リッジ回帰](#2.1.4-リッジ回帰)**\n",
    "    - **[2.1.5 ElasticNet回帰](#2.1.5-ElasticNet回帰)**\n",
    "<br><br>\n",
    "- **[2.2 まとめ問題(提出不要)](#2.2-まとめ問題(提出不要))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "HJTWu07blWG"
   },
   "source": [
    "## 2.1 モデルの汎化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5010,
    "exerciseId": "Hkq2Ui8lG",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.1 汎化とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "回帰分析の目的は、過去のデータからモデルを学習し、未知のデータを予測することです。  Chapter1では回帰分析を過去のデータを用いて値を予測するようにモデルを設定しました。\n",
    "\n",
    "しかし、過去のデータは株価変動や売り上げ変動などの事象を完全に説明しているわけではありません。  \n",
    "データの予測には幅が存在し、また入力するデータが同じでも実際の結果が変わってしまうということもあり得ます。\n",
    "\n",
    "<b>過去のデータを信頼しすぎることによってデータの予測に破綻</b>が生じる場合があります。  \n",
    "これを <b style='color: #AA0000'>過学習</b>と呼び、予測精度が下がってしまう原因となります。\n",
    "\n",
    "過学習を防ぐために取られるアプローチが <b style='color: #AA0000'>汎化</b>です。汎化を意識したモデルを作ることで、学習に使ったデータに適合しすぎず、一般的なケースに対応できるようになります。具体的な汎化手法は今後のセッションを見てみましょう。\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1548677697407119.png\" width=500>\n",
    "\n",
    "<b><center>図2.1.1-1 汎化</center></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下の文章のうち汎化について正しいものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- モデルの予測精度を下げるために汎化が行われる。\n",
    "- 過去のデータに特化した予測が行えるようにすること。\n",
    "- モデルによるデータの推定を一般化すること。\n",
    "- モデルは複雑な方が関係性を説明できて良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 汎化によってデータの関係性はよりシンプルになる傾向があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "モデルによるデータの推定を一般化すること。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5010,
    "exerciseId": "Bkl93IiUgz",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.2 正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "線形回帰では、 汎化手法として<b style='color: #AA0000'>正則化</b>が用いられます。\n",
    "正則化とは、回帰分析を行うモデルに対し、モデルが推定したデータ同士の関係性の複雑さに対してペナルティを加えることによってモデルが推定するデータ同士の関係性を一般化しようとするアプローチです。\n",
    "\n",
    "正則化としてはL1正則化とL2正則化が良く用いられます。\n",
    "\n",
    "\n",
    "<b>L1正則化</b>は「予測に影響を及ぼしにくいデータ」にかかる係数をゼロに近づけることで、疎なモデルを得ることができるようにする手法です。<b>データとして余分な情報がたくさん存在するようなデータ</b>の回帰分析を行う際に重宝します。また、特徴量削減の手法として用いることもできます。\n",
    "\n",
    "<b>L2正則化</b>は係数の大きさが大きくなりすぎないように制限する手法であり、過学習を抑えるために用いられます。学習の結果得られる係数が不自然に大きくならないので<b>滑らかなモデルを得やすい</b>（汎化しやすい）という特徴があります。\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1548753356777627.png\" width=500>\n",
    "\n",
    "<b><center>図2.1.2-1 L1正則化（左）とL2正則化（右）のイメージ</center></b>\n",
    "\n",
    "L1正則化とL2正則化は図2.1.2-1のようにイメージできます。緑で示した部分が正則化の条件であり、青の等高線が正則化をしない場合の損失関数になります。正則化をしない場合は係数$w_1$と$w_2$は青丸の位置に収束します。しかし、正則化を行うと、条件として緑の部分にも近づける必要ができるので係数$w_1$と$w_2$はちょうどいい点（オレンジの点）に収束するようになります。<br>\n",
    "上記で説明したように、図ではL1正則化を用いると$w_1=0$の点に収束しています。また、L2正則化を用いると$w_1$も$w_2$も青の点よりも小さくなるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 正則化について述べたもののうち正しいものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "choices"
   },
   "source": [
    "- 予測精度を上げるためにデータに対して行う処理のこと。\n",
    "- 予測に用いるデータの比重を下げること。\n",
    "- L1正則化は予測するデータとの関係性が高いものを削ってモデルの説明力を高めたものです。\n",
    "- L2正則化はデータの値の範囲を揃えるように係数を操作することで説明力を高めようとするアプローチです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- L1正則化とL2正則化の違いも理解しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "source": [
    "L2正則化はデータの値の範囲を揃えるように係数を操作することで説明力を高めようとするアプローチです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5010,
    "exerciseId": "B1Z9h8oIxz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.3 ラッソ回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>ラッソ回帰</b>とは<b>L1正則化を行いながら線形回帰の適切なパラメータを設定する回帰モデル</b>です。\n",
    "\n",
    "機械学習では予測に用いるデータ同士の関連性を人間が認識しにくい場合があります。<b>L1正則化</b>では、データとして余分な情報がたくさん存在するようなデータの回帰分析を行う際に重宝すると確認しました。そのため、<b>データセットの数</b>（行数）に比べて、<b>パラメータの数</b>（列数）が多いなどといった場合には、ラッソ回帰を利用するのが良いでしょう。\n",
    "\n",
    "scikit-learnのlinear_modelモジュール内にある`Lasso()`というモデルがラッソ回帰のモデルにあたります。\n",
    "\n",
    "```Python\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=100, n_features=100, n_informative=60, n_targets=1, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model = Lasso()\n",
    "model.fit(train_X, train_y)\n",
    "print(model.score(test_X, test_y))\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> 出力結果\n",
    "0.967921092594\n",
    "```\n",
    "\n",
    "線形回帰の`model =LinearRegression()`を`model = Lasso()`に変更するだけで、ラッソ回帰で分析ができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 正則化を行わない線形回帰とラッソ回帰のモデルの比較をしてください。\n",
    "- 余計な情報が多分に含まれたデータを渡しますので線形回帰とラッソ回帰を行い、`test_X`, `test_y`に対する決定係数を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "X, y = make_regression(n_samples=100, n_features=100, n_informative=60, n_targets=1, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# 線形回帰\n",
    "model = \n",
    "\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"線形回帰:{}\".format(model.score(test_X, test_y)))\n",
    "\n",
    "# ラッソ回帰\n",
    "model = \n",
    "\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"ラッソ回帰:{}\".format(model.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 線形回帰とラッソ回帰の学習の流れは同じです。\n",
    "- 今回のデータは予測に用いるデータが100のうち余分なデータが40あるデータです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "X, y = make_regression(n_samples=100, n_features=100, n_informative=60, n_targets=1, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# 線形回帰\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"線形回帰:{}\".format(model.score(test_X, test_y)))\n",
    "\n",
    "# ラッソ回帰\n",
    "model = Lasso()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"ラッソ回帰:{}\".format(model.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5010,
    "exerciseId": "SJz9hLiIez",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.4 リッジ回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>リッジ回帰</b>とは<b>L2正則化</b>を行いながら線形回帰の適切なパラメータを設定する回帰モデルです。\n",
    "\n",
    "リッジ回帰には、シンプルな線形回帰モデルよりも<b>滑らかなモデルを得やすい</b>（汎化しやすい）という特徴がありました。<br>\n",
    "\n",
    "scikit-learnのlinear_modelモジュール内にある`Ridge()`というモデルがリッジ回帰のモデルにあたります。\n",
    "\n",
    "実装方法は、シンプルな線形回帰モデル、ラッソ回帰と全く同じでモデル名を差し替えるだけでOKです。\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=100, n_features=50, n_informative=50, n_targets=1, noise=100.0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(train_X, train_y)\n",
    "print(model.score(test_X, test_y))\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> 出力結果\n",
    "0.90786283239\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 線形回帰とリッジ回帰によるモデルの違いを比較してください。\n",
    "- データが渡されるので`test_X`, `test_y`に対する決定係数を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "X, y = make_regression(n_samples=100, n_features=50, n_informative=50, n_targets=1, noise=100.0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# 線形回帰\n",
    "model = \n",
    "\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"線形回帰:{}\".format(model.score(test_X, test_y)))\n",
    "\n",
    "# リッジ回帰\n",
    "model = \n",
    "\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"リッジ回帰:{}\".format(model.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- リッジ回帰もモデルの学習の流れは線形回帰と同じです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "X, y = make_regression(n_samples=100, n_features=50, n_informative=50, n_targets=1, noise=100.0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# 線形回帰\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"線形回帰:{}\".format(model.score(test_X, test_y)))\n",
    "\n",
    "# リッジ回帰\n",
    "model = Ridge()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_X, test_yに対する決定係数を出力してください\n",
    "print(\"リッジ回帰:{}\".format(model.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5010,
    "exerciseId": "Sy75hIiLez",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.5 ElasticNet回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "さて、最後にElasticNet回帰を紹介します。<b style='color: #AA0000'>ElasticNet回帰</b>とは、ラッソ回帰とリッジ回帰を組み合わせて正則化項を作るモデルとなります。\n",
    "\n",
    "メリットとしては、ラッソ回帰で取り扱った余分な情報がたくさん存在するようなデータに対して<b>情報を取捨選択してくれる点</b>と、リッジ回帰で取り扱った <b>滑らかなモデルを得やすい</b>（汎化しやすい）点の組み合わせとなるので、両方のメリットをバランスよく用いてモデルを作りたい時にはベストな手法となります。\n",
    "\n",
    "ElasticNet回帰を使ってモデルを構築する場合、いままでと同じように以下のようにモデルを呼び出せばOKです。\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet()\n",
    "```\n",
    "\n",
    "なお、scikit-learnのElasticNet()には`l1_ratio`という引数を指定できます。\n",
    "\n",
    "```python\n",
    "model = ElasticNet(l1_ratio=0.3)\n",
    "```\n",
    "\n",
    "以上のように設定すると、L1正則化とL2正則化の割合を指定することができます。以上の場合、L1正則化が30％、L2正則化が70％効いていることを示しています。（指定しないと、丁度半々のElasticNet回帰モデルで指定されます。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ElasticNet回帰に関して説明している以下の文章のうち間違っているものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- Lasso回帰とRidge回帰を組み合わせて正則化項を作るモデル。\n",
    "- Lasso回帰の「余分な情報がたくさん存在するようなデータに対して情報を取捨選択してくれる」メリットがある。\n",
    "- Ridge回帰の「滑らかなモデルを得やすい（汎化しやすい）」メリットがある。\n",
    "- L1正則化とL2正則化の割合は常に半々である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `l1_ratio`という引数の使い方を確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "L1正則化とL2正則化の割合は常に半々である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam",
    "timeout": 10
   },
   "source": [
    "## 2.2 まとめ問題(提出不要)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "これまでの課題ではかなり回帰の決定係数が高くなるように生成されたデータを用いて学習を行いました。\n",
    "\n",
    "実際のデータは線形では決定できないくらい複雑なモデルになると思います。  \n",
    "整形されたデータではありますが生のデータに近いデータセットを用いた学習を行ってみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ボストンの家屋に関するデータセットが渡されます。\n",
    "- ラッソ回帰やリッジ回帰を用いて決定係数を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールのインポート\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 以下に必要なモジュールを追記してください\n",
    "\n",
    "\n",
    "# データの取得\n",
    "boston_data = load_boston()\n",
    "train_X, test_X, train_y, test_y = train_test_split(boston_data.data, boston_data.target, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 今回はモジュールのインポートを行っていません。必要なモジュールをインポートしてください。\n",
    "- データセットに関する詳しい情報は`print(boston_data.DESCR)`を実行してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールのインポート\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 以下に必要なモジュールを追記してください\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# データの取得\n",
    "boston_data = load_boston()\n",
    "train_X, test_X, train_y, test_y = train_test_split(boston_data.data, boston_data.target, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください。\n",
    "# 線形回帰\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "print(\"線形回帰:{}\".format(model.score(test_X, test_y)))\n",
    "\n",
    "# ラッソ回帰\n",
    "model = Lasso()\n",
    "model.fit(train_X, train_y)\n",
    "print(\"ラッソ回帰:{}\".format(model.score(test_X, test_y)))\n",
    "\n",
    "# リッジ回帰\n",
    "model = Ridge()\n",
    "model.fit(train_X, train_y)\n",
    "print(\"リッジ回帰:{}\".format(model.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "解答例の三種類では線形回帰が一番モデルを説明できているという結果になりました。  \n",
    "整形がすでに行われているためさらに正則化を行う必要がなかったと思われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}