{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()で可視化されない人はこのセルを実行してください。\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "Hy-m_AQblbz",
    "id": "chapter_name"
   },
   "source": [
    "# ハイパーパラメーターとチューニング(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[3.1 決定木のハイパーパラメーター](#3.1-決定木のハイパーパラメーター)**\n",
    "    - **[3.1.1 パラメーター-max_depth](#3.1.1-パラメーター-max_depth)**\n",
    "    - **[3.1.2 パラメーター-random_state](#3.1.2-パラメーター-random_state)**\n",
    "<br><br>\n",
    "- **[3.2 ランダムフォレストのハイパーパラメーター](#3.2-ランダムフォレストのハイパーパラメーター)**\n",
    "    - **[3.2.1 パラメーター-n_estimators](#3.2.1-パラメーター-n_estimators)**\n",
    "    - **[3.2.2 パラメーター-max_depth](#3.2.2-パラメーター-max_depth)**\n",
    "    - **[3.2.3 パラメーター-random_state](#3.2.3-パラメーター-random_state)**\n",
    "<br><br>\n",
    "- **[3.3 k-NNのハイパーパラメーター](#3.3-k-NNのハイパーパラメーター)**\n",
    "    - **[3.3.1 パラメーター-n_neighbors](#3.3.1-パラメーター-n_neighbors)**\n",
    "<br><br>\n",
    "- **[3.4 チューニングの半自動化](#3.4-チューニングの半自動化)**\n",
    "    - **[3.4.1 グリッドサーチ](#3.4.1-グリッドサーチ)**\n",
    "    - **[3.4.2 ランダムサーチ](#3.4.2-ランダムサーチ)**\n",
    "    - **[3.4.3 モデルに基づくハイパーパラメータの最適化](#3.4.3-モデルに基づくハイパーパラメータの最適化)**\n",
    "<br><br>\n",
    "- **[3.5 まとめ問題(提出不要)](#3.5-まとめ問題(提出不要))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "S1MQdA7Zgbz"
   },
   "source": [
    "## 3.1 決定木のハイパーパラメーター"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "H1pe9nIsUgf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.1.1 パラメーター max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    " <b style='color: #AA0000'>max_depth</b>は学習時にモデルが学習する木の<b>深さの最大値</b>を表すパラメーターです。\n",
    "\n",
    " `max_depth`の値が設定されていない時、木は教師データの分類がほぼ終了するまでデータを分割します。\n",
    "\n",
    "このため教師データを過剰に信頼し学習した一般性の低いモデルとなってしまいます。\n",
    "\n",
    "また、値が大きすぎても同じように分類が終了した段階で木の成長は止まるので上記の状態と同じになります。\n",
    "    \n",
    "`max_depth` を設定し木の高さを制限することを決定木の枝刈りと呼びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 決定木の`max_depth`の違いによる分類の正解率をグラフで表してみましょう。\n",
    "- `depth_list` というリストが渡されますので、`max_depth` に `depth_list` 内の値を順次代入しテスト用データの正解率を出し、`max_depth` との関係をプロットしたグラフを出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# max_depthの値の範囲(1から10)\n",
    "depth_list = [i for i in range(1, 11)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "# max_depthを変えながらモデルを学習\n",
    "for max_depth in depth_list:\n",
    "    model = \n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# コードの編集はここまでです。\n",
    "# グラフのプロット\n",
    "plt.plot(depth_list, accuracy)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by changing max_depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってdepth_listの要素を取り出します。\n",
    "- max_depthのチューニングはモデル構築時に行います。以下のコードも参照してください。  \n",
    "`model = DecisionTreeClassifier(max_depth=1, random_state=42)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# max_depthの値の範囲(1から10)\n",
    "depth_list = [i for i in range(1, 11)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "# max_depthを変えながらモデルを学習\n",
    "for max_depth in depth_list:\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# コードの編集はここまでです。\n",
    "# グラフのプロット\n",
    "plt.plot(depth_list, accuracy)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by changing max_depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "HJCx53Lo8xM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.1.2 パラメーター random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>random_state</b>は決定木の<b>学習過程に直接関わるパラメーター</b>です。\n",
    "\n",
    "決定木の分割は分割を行う時点でよくデータの分類を説明できる要素の値を見つけ、データの分割を行うのですが、そのような値の候補はたくさん存在するため、 `random_state` による乱数の生成により、その候補を決めています。\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- random_stateは決定木においてどのようなパラメーターでしょうか。\n",
    "- 次の選択肢から選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 決定木を分割する値そのもの\n",
    "1. 決定木を分割するために用いる乱数\n",
    "1. 決定木を分割するために用いる乱数を生成するための値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 決定木では乱数によって学習結果が異なることがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "決定木を分割するために用いる乱数を生成するための値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "B1mm_AQWe-z"
   },
   "source": [
    "## 3.2 ランダムフォレストのハイパーパラメーター"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "H1yZ5n8sLef",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.2.1 パラメーター n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "ランダムフォレストの特徴として<b>複数の簡易決定木による多数決で結果が決定される</b>というものが挙げられますが、その簡易決定木の個数を決めるのがこの<b style='color: #AA0000'>n_estimators</b>というパラメーターです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- RandomForestの `n_estimators` の違いによる分類の正解率をグラフで表してみましょう。\n",
    "- `n_estimators_list` というリストが渡されますので、`n_estimators` に` n_estimators_list` 内の値を順次代入しテスト用データの正解率を出し、`n_estimators` との関係をプロットしたグラフを出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=4, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# n_estimatorsの値の範囲(1から20)\n",
    "n_estimators_list = [i for i in range(1, 21)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "# n_estimatorsを変えながらモデルを学習\n",
    "for n_estimators in n_estimators_list:\n",
    "    model = \n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフのプロット\n",
    "plt.plot(n_estimators_list, accuracy)\n",
    "plt.title(\"accuracy by n_estimators increasement\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってn_estimators_listの要素を取り出します。\n",
    "- n_estimatorsのチューニングはモデル構築時に行います。以下のコードも参照してください。  \n",
    "`model = RandomForestClassifier(n_estimators=1, random_state=42)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=4, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# n_estimatorsの値の範囲(1から20)\n",
    "n_estimators_list = [i for i in range(1, 21)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "# n_estimatorsを変えながらモデルを学習\n",
    "for n_estimators in n_estimators_list:\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフのプロット\n",
    "plt.plot(n_estimators_list, accuracy)\n",
    "plt.title(\"accuracy by n_estimators increasement\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "HygZq3Uj8gf",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.2.2 パラメーター max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "ランダムフォレストは簡易決定木を複数作るので決定木に関するパラメーターを設定することが可能です。<br>\n",
    "<b style='color: #AA0000'>max_depth</b>は、決定木の過学習を防ぐためのパラメーターです。<br>\n",
    "ランダムフォレストにおいては<b>通常の決定木より小さな値を入力します</b>。\n",
    "\n",
    "簡易決定木の分類の多数決というアルゴリズムであるため一つ一つの決定木に対して厳密な分類を行うより着目要素を絞り俯瞰的に分析を行うことで学習の効率の良さと高い精度を保つことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "なぜランダムフォレストでは決定木より `max_depth` を小さく設定するのでしょうか。\n",
    "以下の選択肢より選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. ランダムフォレストが決定木ほど厳密なモデルではないため。\n",
    "1. max_depthによって予測結果が変わることがないため。\n",
    "1. 教師データに対する過剰な学習を防ぐため。\n",
    "1. max_depthは多数決に寄与するパラメーターであるため。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- ランダムフォレストは予測精度向上のため複数の決定木を作成しその決定木の多数決で決めるモデルです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "教師データに対する過剰な学習を防ぐため。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "B1ZW5nUi8eM",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 20
   },
   "source": [
    "### 3.2.3 パラメーター random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>random_state</b>はランダムフォレストにおいても重要なパラメーターです。\n",
    "\n",
    "ランダムフォレストの名前の通り結果の固定のみならず、決定木のデータの分割や用いる<b>要素の決定</b>など多くの場面で<b>乱数が寄与</b>するこの手法ではこのパラメーターによって分析結果が大きく異なります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ランダムフォレストのrandom_stateの違いによる分類の正解率をグラフで表してみましょう。\n",
    "- `r_seeds`というリストが渡されますので、`random_state`に`r_seeds`内の値を順次代入しテスト用データの正解率を出し、`random_state`との関係をプロットしたグラフを出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=4, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# r_seedsの値の範囲(0から99)\n",
    "r_seeds = [i for i in range(100)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "\n",
    "# random_stateを変えながらモデルを学習\n",
    "for seed in r_seeds:\n",
    "    model = \n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフのプロット\n",
    "plt.plot(r_seeds, accuracy)\n",
    "plt.xlabel(\"seed\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by changing seed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってr_seedsの要素を取り出します。\n",
    "- random_stateのチューニングはモデル構築時に行います。以下のコードも参照してください。  \n",
    "`model = RandomForestClassifier(random_state=42)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=4, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# r_seedsの値の範囲(0から99)\n",
    "r_seeds = [i for i in range(100)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "\n",
    "# random_stateを変えながらモデルを学習\n",
    "for seed in r_seeds:\n",
    "    model = RandomForestClassifier(random_state=seed)\n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフのプロット\n",
    "plt.plot(r_seeds, accuracy)\n",
    "plt.xlabel(\"seed\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by changing seed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "rk4QORm-xZM"
   },
   "source": [
    "## 3.3 k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "Skzb5hLjIgG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.3.1 パラメーター n_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>n_neighbors</b>はk-NNの$k$の値のことです。\n",
    "つまり、結果予測の際に使う類似データの個数を決めるパラメーターです。\n",
    "    \n",
    "`n_neighbors` の数が多すぎると類似データとして選ばれるデータの類似度に幅が出るため、分類範囲の狭いカテゴリーがうまく分類されないということが起こります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- k-NNの`n_neighbors`の違いによる分類の正解率をグラフで表してみましょう。\n",
    "- `k_list`というリストが渡されますので、`n_neighbors`に`k_list`内の値を順次代入しテスト用データの正解率を出し、`n_neighbors`との関係をプロットしたグラフを出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=4, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# n_neighborsの値の範囲(1から10)\n",
    "k_list = [i for i in range(1, 11)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "\n",
    "# n_neighborsを変えながらモデルを学習\n",
    "for k in k_list:\n",
    "    model = \n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフのプロット\n",
    "plt.plot(k_list, accuracy)\n",
    "plt.xlabel(\"n_neighbor\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by changing n_neighbor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってk_listの要素を取り出します。\n",
    "- n_neighborsのチューニングはモデル構築時に行います。以下のコードも参照してください。  \n",
    "`model = KNeighborsClassifier(n_neighbors=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=4, n_informative=3, n_redundant=0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# n_neighborsの値の範囲(1から10)\n",
    "k_list = [i for i in range(1, 11)]\n",
    "\n",
    "# 正解率を格納するからリストを作成\n",
    "accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください\n",
    "\n",
    "# n_neighborsを変えながらモデルを学習\n",
    "for k in k_list:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(train_X, train_y)\n",
    "    accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフのプロット\n",
    "plt.plot(k_list, accuracy)\n",
    "plt.xlabel(\"n_neighbor\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by changing n_neighbor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "HkBmOAQWgZG"
   },
   "source": [
    "## 3.4 チューニングの自動化 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "r1XWchIoLlf",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.4.1 グリッドサーチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "これまで主要な手法の中でよく使われるパラメーターを紹介してきました。\n",
    "しかしこれら全てのパラメーターを都度変えて結果を確認するのは時間と手間がかかります。\n",
    "    \n",
    "そこで、パラメーターの範囲を指定して一番結果の良かったパラメーターセットを計算機に見つけてもらうという方法を使います。\n",
    "主な方法は2つ、<b style='color: #AA0000'>グリッドサーチ</b>と<b style='color: #AA0000'>ランダムサーチ</b>です。\n",
    "    \n",
    "グリッドサーチは調整したいハイパーパラメーターの値の<b>候補を明示的に複数指定</b>し、パラメーターセットを作成し、その時のモデルの評価を繰り返すことでモデルとして最適なパラメーターセットを作成するために用いられる方法です。\n",
    "    \n",
    "値の候補を明示的に指定するためパラメーターの値に文字列や整数、True or Falseといった数学的に連続ではない値をとるパラメーターの探索に向いています。\n",
    "ただしパラメーターの候補を網羅するようにパラメーターセットが作成されるため多数のパラメーターを同時にチューニングするのには不向きです。\n",
    "    \n",
    "コードは以下のようになります。\n",
    "プログラムの実行には時間がかかりますのでご注意ください。\n",
    "    \n",
    "```python\n",
    "import scipy.stats\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = load_digits()\n",
    "train_X, test_X, train_y, test_y = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "# パラメーターの値の候補を設定\n",
    "model_param_set_grid = {SVC(): {\"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                                \"C\": [10 ** i for i in range(-5, 5)],\n",
    "                                \"decision_function_shape\": [\"ovr\", \"ovo\"],\n",
    "                                \"random_state\": [42]}}\n",
    "              \n",
    "max_score = 0\n",
    "best_param = None\n",
    "\n",
    "# グリッドサーチでパラメーターサーチ\n",
    "for model, param in model_param_set_grid.items():\n",
    "    clf = GridSearchCV(model, param)\n",
    "    clf.fit(train_X, train_y)\n",
    "    pred_y = clf.predict(test_X)\n",
    "    score = f1_score(test_y, pred_y, average=\"micro\")\n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        best_model = model.__class__.__name__\n",
    "        best_param = clf.best_params_\n",
    "                        \n",
    "print(\"パラメーター:{}\".format(best_param))\n",
    "print(\"ベストスコア:\",max_score)\n",
    "svm = SVC()\n",
    "svm.fit(train_X, train_y)\n",
    "print()\n",
    "print('調整なし')\n",
    "print(svm.score(test_X, test_y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のうちグリッドサーチの特徴ではないものを選択してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 値の候補を列挙し、パラメーターサーチをする手法の一つ。\n",
    "1. 候補となる値を全てパラメーターとして試し、一番学習精度の良いモデルを返す。\n",
    "1. 実行に時間がかかる。\n",
    "1. パラメーターサーチとしては唯一の手法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 値の候補を逐次的に全探索するため実行に時間がかかります。\n",
    "- パラメーターサーチの目的はモデルの予測精度が高くなるようなパラメーターを見つけることです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "パラメーターサーチとしては唯一の手法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "SyNW5n8oUef",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 3.4.2 ランダムサーチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "グリッドサーチは値の候補を指定してその上でパラメーターを調整しました。\n",
    "\n",
    "<b style='color: #AA0000'>ランダムサーチ</b>はパラメーターが<b>取りうる値の範囲</b>を指定し、確率で決定されたパラメーターセットを用いてモデルの評価を行うことを繰り返すことによって最適なパラメーターセットを探す方法です。\n",
    "\n",
    "値の範囲の指定はパラメーターの確率関数を指定するというものになります。\n",
    "    \n",
    "\n",
    "パラメーターの確率関数としてscipy.statsモジュールの確率関数がよく用いられます。\n",
    "\n",
    "コードは以下の通りです。\n",
    "```python\n",
    "import scipy.stats\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = load_digits()\n",
    "train_X, test_X, train_y, test_y = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "# パラメーターの値の候補を設定\n",
    "model_param_set_random =  {SVC(): {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "        \"C\": scipy.stats.uniform(0.00001, 1000),\n",
    "        \"decision_function_shape\": [\"ovr\", \"ovo\"],\n",
    "        \"random_state\": scipy.stats.randint(0, 100)\n",
    "    }}\n",
    "\n",
    "max_score = 0\n",
    "best_param = None\n",
    "\n",
    "# ランダムサーチでパラメーターサーチ\n",
    "for model, param in model_param_set_random.items():\n",
    "    clf = RandomizedSearchCV(model, param)\n",
    "    clf.fit(train_X, train_y)\n",
    "    pred_y = clf.predict(test_X)\n",
    "    score = f1_score(test_y, pred_y, average=\"micro\")\n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        best_param = clf.best_params_\n",
    "        \n",
    "print(\"パラメーター:{}\".format(best_param))\n",
    "print(\"ベストスコア:\",max_score)\n",
    "svm = SVC()\n",
    "svm.fit(train_X, train_y)\n",
    "print()\n",
    "print('調整なし')\n",
    "print(svm.score(test_X, test_y))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のうちランダムサーチについて説明している文章はどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. データをランダムに学習し、モデルの精度を上げる方法。\n",
    "1. パラメーターの範囲を設定し、範囲内でランダムに値を選択することでモデルの予測精度を向上させる手法。\n",
    "1. 使用するハイパーパラメーターをランダムに決定しモデルの予測精度を向上させる方法。\n",
    "1. モデルの予測結果をランダムに変更することで予測精度を上げる方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- パラメーターサーチの目的はモデルの予測精度を向上させるようなハイパーパラメーターの値を決定することにあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "パラメーターの範囲を設定し、範囲内でランダムに値を選択することでモデルの予測精度を向上させる手法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 モデルに基づくハイパーパラメータの最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　ニューラルネットは基本的に勾配法（最急降下法）と呼ばれる方法で、損失関数を減少させる方向に少しずつ進んでいきます。通常ニューラルネットには多くの鞍点（擬似的な解）があり、鞍点にハマってしまうと勾配が0になり動けなくなるため、本来の解に辿り付けません。\n",
    " \n",
    "　よって、勾配法は様々な改良された手法が生み出されています。損失関数に対して万能な最適化法など存在しません。（ノーフリーランチ定理）また、損失関数はタスクやデータに応じて変わるため、最適化は理論より先に試していく必要もあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 次のうちハイパーパラメータ調整の難点を正しく説明している文章はどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 最適なハイパーパラメータは勾配法（最急降下法）を用いれば必ず見つかる。\n",
    "1. ニューラルネットには多くの鞍点があり、鞍点の傾きは負である。\n",
    "1. 損失関数はタスクやデータに応じて変わるため、どの手法を使うかは試して決める必要がある。\n",
    "1. 勾配法を改良した最も良い最適化法が存在するので、一般にそれが使われる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ニューラルネットワークは鞍点が存在するため、勾配法では学習が停滞することがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数はタスクやデータに応じて変わるため、どの手法を使うかは試して決める必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 3.5 まとめ問題(提出不要)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "グリッドサーチやランダムサーチは時間こそかかりますがパラメーターの調整は正解率に大きく関わります。  \n",
    "各モデルに対してパラメーターサーチを実行できるようになるとモデルの精度の向上が見込めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次に示す値を用いてランダムサーチによるパラメーター探索を行ってください。\n",
    "    - チューニングを行う手法はSVM、決定木、ランダムフォレストです。\n",
    "    - SVMは`SVC()`を用いて、kernelを\"linear\"、\"rbf\"、\"poly\"、\"sigmoid\"の中から、Cを0.01,0.1,1.0,10,100の中から選んでパラメータを調整してください。random_stateは固定して良いです。\n",
    "    - 決定木はmax_depthを1から10の範囲の整数、random_stateを0から100の範囲の整数でパラメータを調整してください。\n",
    "    - ランダムフォレストはn_estimatorsを10から100の範囲の整数、max_depthを1から10の範囲の整数、random_stateを0から100の範囲の整数でパラメータを調整してください。\n",
    "    \n",
    "- 出力は各モデルの名前とその時のtest_X, test_yに対する正解率を  \n",
    "モデル名  \n",
    "正解率  \n",
    "となるようにしてください。\n",
    "\n",
    "<!-- <span style=\"color: red; \">出力としては、最適パラメーター時の予測精度を出力した方が良いと思います。パラメーター探索の目的はそこにあるので。</span>  修正 -->  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 必要データの前処理\n",
    "vote_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\"\n",
    "s = requests.get(vote_data_url).content\n",
    "vote_data = pd.read_csv(io.StringIO(s.decode('utf-8')),header=None)\n",
    "vote_data.columns = ['Class Name',\n",
    "                     'handicapped-infants',\n",
    "                     'water-project-cost-sharing',\n",
    "                     'adoption-of-the-budget-resolution',\n",
    "                     'physician-fee-freeze',\n",
    "                     'el-salvador-aid',\n",
    "                     'religious-groups-in-schools',\n",
    "                     'anti-satellite-test-ban',\n",
    "                     'aid-to-nicaraguan-contras',\n",
    "                     'mx-missile',\n",
    "                     'immigration',\n",
    "                     'synfuels-corporation-cutback',\n",
    "                     'education-spending',\n",
    "                     'superfund-right-to-sue',\n",
    "                     'crime',\n",
    "                     'duty-free-exports',\n",
    "                     'export-administration-act-south-africa']\n",
    "label_encode = preprocessing.LabelEncoder()\n",
    "vote_data_encode = vote_data.apply(lambda x: label_encode.fit_transform(x))\n",
    "X = vote_data_encode.drop('Class Name', axis=1)\n",
    "Y = vote_data_encode['Class Name']\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,Y, random_state=50)\n",
    "\n",
    "# 以下にコードを記述\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- パラメーターはPython標準の辞書型のキーをパラメーター、値を値の候補が入ったリストとしてRandomizedSearchCVに渡します。\n",
    "- `zip()`関数を使えば複数のリストの要素をまとめて取得することが出来ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールのインポート\n",
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 必要データの前処理\n",
    "vote_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\"\n",
    "s = requests.get(vote_data_url).content\n",
    "vote_data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None)\n",
    "vote_data.columns = ['Class Name',\n",
    "                     'handicapped-infants',\n",
    "                     'water-project-cost-sharing',\n",
    "                     'adoption-of-the-budget-resolution',\n",
    "                     'physician-fee-freeze',\n",
    "                     'el-salvador-aid',\n",
    "                     'religious-groups-in-schools',\n",
    "                     'anti-satellite-test-ban',\n",
    "                     'aid-to-nicaraguan-contras',\n",
    "                     'mx-missile',\n",
    "                     'immigration',\n",
    "                     'synfuels-corporation-cutback',\n",
    "                     'education-spending',\n",
    "                     'superfund-right-to-sue',\n",
    "                     'crime',\n",
    "                     'duty-free-exports',\n",
    "                     'export-administration-act-south-africa']\n",
    "label_encode = preprocessing.LabelEncoder()\n",
    "vote_data_encode = vote_data.apply(lambda x: label_encode.fit_transform(x))\n",
    "X = vote_data_encode.drop('Class Name', axis=1)\n",
    "Y = vote_data_encode['Class Name']\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, Y, random_state=50)\n",
    "\n",
    "# 以下にコードを記述\n",
    "# for文で処理をさせたいのでモデル名、モデルのオブジェクト、パラメーターリストを全てリストに入れる\n",
    "models_name = [\"SVM\", \"決定木\", \"ランダムフォレスト\"]\n",
    "models = [SVC(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "params = [{\"C\": [0.01, 0.1, 1.0, 10, 100],\n",
    "           \"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "           \"random_state\": [42]},\n",
    "          {\"max_depth\": scipy.stats.randint(1,11),\n",
    "           \"random_state\": scipy.stats.randint(0,101)},\n",
    "          {\"n_estimators\": scipy.stats.randint(10,101),\n",
    "           \"max_depth\": scipy.stats.randint(1,11),\n",
    "           \"random_state\": scipy.stats.randint(0,101)}]\n",
    "\n",
    "for name, model, param in zip(models_name, models, params):\n",
    "    clf = RandomizedSearchCV(model, param)\n",
    "    clf.fit(train_X, train_y)\n",
    "    print(name)\n",
    "    print(clf.score(test_X, test_y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "- グリッドサーチやランダムサーチなどのハイパーパラメータチューニングはモデルの精度の向上において非常に有用です。For文を回すだけで実装できる便利な手法なので、ここでしっかりと理解しておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "311.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}