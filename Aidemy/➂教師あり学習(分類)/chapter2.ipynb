{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()で可視化されない人はこのセルを実行してください。\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "By3zOAX-ebM",
    "id": "chapter_name"
   },
   "source": [
    "# ハイパーパラメーターとチューニング(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[2.1 ハイパーパラメーターとチューニング](#2.1-ハイパーパラメーターとチューニング)**\n",
    "    - **[2.1.1 ハイパーパラメーターとは](#2.1.1-ハイパーパラメーターとは)**\n",
    "    - **[2.1.2 チューニングとは](#2.1.2-チューニングとは)**\n",
    "<br><br>\n",
    "- **[2.2 ロジスティック回帰のハイパーパラメーター](#2.2-ロジスティック回帰のハイパーパラメーター)**\n",
    "    - **[2.2.1 パラメーター C](#2.2.1-パラメーター-C)**\n",
    "    - **[2.2.2 パラメーター penalty](#2.2.2-パラメーター-penalty)**\n",
    "    - **[2.2.3 パラメーター multi_class](#2.2.1-パラメーター-multi_class)**\n",
    "    - **[2.2.4 パラメーター random_state](#2.2.1-パラメーター-random_state)**\n",
    "<br><br>\n",
    "- **[2.3 線形SVMのハイパーパラメーター](#2.3-線形SVMのハイパーパラメーター)**\n",
    "    - **[2.3.1 パラメーター C](#2.3.1-パラメーター-C)**\n",
    "    - **[2.3.2 パラメーター penalty](#2.3.2-パラメーター-penalty)**\n",
    "    - **[2.3.3 パラメーター multi_class](#2.3.1-パラメーター-multi_class)**\n",
    "    - **[2.3.4 パラメーター random_state](#2.3.1-パラメーター-random_state)**\n",
    "<br><br>\n",
    "- **[2.4 非線形SVMのハイパーパラメーター](#2.4-非線形SVMのハイパーパラメーター)**\n",
    "    - **[2.4.1 パラメーター C](#2.2.1-パラメーター-C)**\n",
    "    - **[2.4.2 パラメーター kernel](#2.2.2-パラメーター-kernel)**\n",
    "    - **[2.4.3 パラメーター decision_function_shape](#2.2.1-パラメーター-decision_function_shape)**\n",
    "    - **[2.4.4 パラメーター random_state](#2.2.1-パラメーター-random_state)**\n",
    "<br><br>\n",
    "- **[2.5 まとめ問題(提出不要)](#2.5-まとめ問題(提出不要))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "BJ6zdRXWeZf"
   },
   "source": [
    "## 2.1 ハイパーパラメーターとチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rykx9nUi8xf",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.1 ハイパーパラメーターとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "機械学習においても学習過程全てを自動化することは難しく、人の手でモデルを調整しなければならない場合が存在します。\n",
    "\n",
    "<b style='color: #AA0000'>ハイパーパラメーター</b>とは、機械学習のモデルが持つパラメーターの中で人が調整をしないといけないパラメーターのことです。\n",
    "\n",
    "ハイパーパラメーターは選択した手法によって異なるため、モデルごとに説明をしていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ハイパーパラメーターについて説明しているのは次の文章のうちどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. チューニングすることによって機械学習の精度を上げることができるたった一つのパラメーターのこと。\n",
    "1. モデルの学習によって得られるパラメーターのこと。\n",
    "1. 人間の手によって調整しなければならないパラメーターのこと。\n",
    "1. 調整を行わなくても良いパラメーターのこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "ハイパーパラメーターは人間の手で調整する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "人間の手によって調整しなければならないパラメーターのこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "r1el538i8gf",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.2 チューニングとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "ハイパーパラメーターを調整することを<b style='color: #AA0000'>チューニング</b>と呼びます。\n",
    "調整方法については直接値をモデルに入力すること以外にも、ハイパーパラメーターの値の範囲を指定し、探索的に最適な値を探す方法も存在します。\n",
    "    \n",
    "scikit-learnではモデルの構築時にパラメーターに値を入力することでパラメーターのチューニングが可能です。\n",
    "パラメーターを入力しなかった場合、モデルごとに定められているパラメーターの初期値がそのまま値として指定されます。\n",
    "    \n",
    "コードとしては以下のようなものとなります。\n",
    "\n",
    "```python\n",
    "# 架空のモデルClassifierを例にしたチューニング方法\n",
    "model = Classifier(param1=1.0, param2=True, param3=\"linear\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- とあるモデルClassifierのパラメーター`param1`、`param2`、`param3`にそれぞれ`10`、`False`、`\"set\"`という値を入力することを考えます。\n",
    "- この条件を満たすコードは次のうちどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. `model = Classifier(param1=set, param2=False, param3=10)`\n",
    "1. `model = Classifier(param1=10, param2=False, param3=\"set\")`\n",
    "1. `model = Classifier(param1=10, param2=False, param3=set)`\n",
    "1. `model = Classifier(param1=False, param2=\"set\", param3=10)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `param1=10`となっているものを選びましょう。\n",
    "- `\"set\"`は文字列です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "`model = Classifier(param1=10, param2=False, param3=\"set\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "ByCfuRQbe-G"
   },
   "source": [
    "## 2.2 ロジスティック回帰のハイパーパラメーター"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "r1-x93LoIgf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.1 パラメーター C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "ロジスティック回帰には<b style='color: #AA0000'>C</b>というパラメーターが存在します。<br>\n",
    "このCはモデルが学習する識別境界線が教師データの分類間違いに対してどのくらい厳しくするのかという指標になります。\n",
    "    \n",
    "Cの値が大きいほどモデルは教師データを完全に分類できるような識別線を学習するようになります。\n",
    "しかし教師データに対して過剰なほどの学習を行うために過学習に陥り、訓練データ以外のデータに予測を行うと正解率が下がる場合が多くなります。\n",
    "    \n",
    "Cの値を小さくすると教師データの分類の誤りに寛容になります。\n",
    "分類間違いを許容することで外れ値データに境界線が左右されにくくなりより一般化された境界線を得やすくなります。\n",
    "ただし、外れ値の少ないデータでは境界線がうまく識別できていないものになってしまう場合もあります。\n",
    "また、極端に小さくてもうまく境界線が識別できません。\n",
    "    \n",
    "<b>scikit-learnのロジスティック回帰モデルのCの初期値は1.0です。</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- Cの値が変化することによってどのくらいモデルの正解率が変わるかをグラフで確認しましょう。ただし`random_state=42`としてください。\n",
    "- Cの値の候補が入っているリスト`C_list`を用いて教師用データの正解率とテスト用データの正解率をプロットしたグラフをmatplotlibを用いてグラフ化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cの値の範囲を設定(今回は1e-5,1e-4,1e-3,0.01,0.1,1,10,100,1000,10000)\n",
    "C_list = [10 ** i for i in range(-5, 5)]\n",
    "\n",
    "# グラフ描画用の空リストを用意\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "for C in C_list:\n",
    "    model = \n",
    "    model.fit(train_X, train_y)\n",
    "    train_accuracy.append(model.score(train_X, train_y))\n",
    "    test_accuracy.append(model.score(test_X, test_y))\n",
    "    \n",
    "# グラフの準備\n",
    "# semilogx()はxのスケールを10のx乗のスケールに変更する\n",
    "plt.semilogx(C_list, train_accuracy, label=\"accuracy of train_data\")\n",
    "plt.semilogx(C_list, test_accuracy, label=\"accuracy of test_data\")\n",
    "plt.title(\"accuracy by changing C\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってC_listに納められているCの値を取り出し、モデルに学習させましょう。\n",
    "- ロジスティック回帰モデルのCの値を調整するにはモデルの構築時に次のように引数にCの値を渡します。  \n",
    "`model = LogisticRegression(C=1.0)`\n",
    "- 訓練データ、テスト用データそれぞれの正解率をそれぞれ`train_accuracy`,`test_accuracy`というリストに入れましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cの値の範囲を設定(今回は1e-5,1e-4,1e-3,0.01,0.1,1,10,100,1000,10000)\n",
    "C_list = [10 ** i for i in range(-5, 5)]\n",
    "\n",
    "# グラフ描画用の空リストを用意\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "for C in C_list:\n",
    "    model = LogisticRegression(C=C, random_state=42)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_accuracy.append(model.score(train_X, train_y))\n",
    "    test_accuracy.append(model.score(test_X, test_y))\n",
    "    \n",
    "# グラフの準備\n",
    "# semilogx()はxのスケールを10のx乗のスケールに変更する\n",
    "plt.semilogx(C_list, train_accuracy, label=\"accuracy of train_data\")\n",
    "plt.semilogx(C_list, test_accuracy, label=\"accuracy of test_data\")\n",
    "plt.title(\"accuracy by changing C\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "Syfl5hUiIgM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.2 パラメーター penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "先ほどのCが分類の誤りの許容度だったのに対し、<b style='color: #AA0000'>penalty</b>はモデルの<b>複雑さに対するペナルティ</b>を表します。\n",
    "\n",
    "penaltyに入力できる値は二つ、「L1」と「L2」です。\n",
    "基本的には「L2」を選べば大丈夫ですが、「L1」を選ぶ方が欲しいデータが得られる場合もあります。\n",
    "    \n",
    "- <b>L1</b><br> \n",
    "    データの特徴量を削減することで識別境界線の一般化を図るペナルティです。\n",
    "- <b>L2</b><br> \n",
    "    データ全体の重みを減少させることで識別境界線の一般化を図るペナルティです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ペナルティについて正しい説明を選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. L1はデータ全体を概観してペナルティを決定する方法である。\n",
    "1. L2はデータの一部を見てモデルに対するペナルティを決定する方法である。\n",
    "1. L1とL2に差はない。\n",
    "1. ペナルティとは、モデルが複雑になりすぎて一般化した問題を解決できなくなることを防ぐために与えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- L1はデータの余分な特徴量を省き、主要な特徴だけでモデルに説明させようとするペナルティの手法です。\n",
    "- L2はデータ全体の重みを減らすことでデータ同士の関係性を弱くしモデルを簡易化しようとするペナルティの手法です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "ペナルティとは、モデルが複雑になりすぎて一般化した問題を解決できなくなることを防ぐために与えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rJme52LiUlf",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.3 パラメーター multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>multi_class</b>は多クラス分類を行う際にモデルがどういった<b>動作を行うかということを決めるパラメーター</b>です。<br>\n",
    "ロジスティック回帰では「`ovr`」、「`multinomial`」の2つの値が用意されています。\n",
    "    \n",
    "- ovr  \n",
    "    クラスに対して「属する/属さない」の二値で応えるような問題に適しています。\n",
    "- multinomial  \n",
    "    各クラスに分類される確率も考慮され、「属する/属さない」だけではなく「どれくらい属する可能性があるか」を扱う問題に適しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- multi_classについて説明している文章のうち正しいのはどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. ovrは各ラベル同士の総当たりでラベルを決定する。\n",
    "1. multi_classは多クラス分類を行う際にどのようにモデルが動作するかを示すパラメーターである。\n",
    "1. multinomialはラベルに関係なくデータが誤分類される確率を考える。\n",
    "1. multi_classを適切に設定すると線形分離可能でないデータも分類可能になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- multi_classは多クラス分類を行う際の挙動を示しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "multi_classは多クラス分類を行う際にどのようにモデルが動作するかを示すパラメーターである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "ryVl92Lo8eM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.4 パラメーター random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "モデルは学習の際にデータをランダムな順番で処理していくのですが、<b style='color: #AA0000'>random_state</b>はその<b>順番を制御するためのパラメーター</b>です。<br>\n",
    "ロジスティック回帰モデルの場合、データによっては処理順によって大きく境界線が変わる場合があります。\n",
    "    \n",
    "また、この<b>random_state</b>の値を固定することで同じデータでの学習結果を保存することができます。<br>\n",
    "当講座でも実行時に結果が変わらないように<b>random_state</b>の値は基本的に固定しています。<br>\n",
    "    \n",
    "当講座で用いているデータはrandom_stateを変えても結果があまり変わりませんが、実際に用いる場合にはデータの再現性も考えてrandom_stateの値を固定するとよいでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- random_stateを固定する理由として正しいのは以下のうちどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 学習の結果が変わらないようにするため。\n",
    "1. データの予測時にランダムで値が変わるようにするため。\n",
    "1. データの選び方をバラバラにするため。\n",
    "1. 学習結果をランダムに入れ替えることでデータの難読化を行うため。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- random_stateが決まるとアルゴリズム内で使われる乱数の値が全て決まります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "学習の結果が変わらないようにするため。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "Bk1XO07WeWz"
   },
   "source": [
    "## 2.3 線形SVMのハイパーパラメーター"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "SJSgcnIsIez",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.3.1 パラメーター C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "SVMにもロジスティック回帰と同様に**分類の誤りの許容度**を示すCがパラメーターとして定義されています。\n",
    "使い方もロジスティック回帰と同様です。\n",
    "    \n",
    "SVMはロジスティック回帰に比べてCによるデータのラベルの予測値変動が激しいです。\n",
    "SVMのアルゴリズムはロジスティック回帰にくらべてより一般化された境界線を得るため、誤りの許容度が上下するとサポートベクターが変化し、ロジスティック回帰よりも正解率が上下することになります。\n",
    "    \n",
    "線形SVMモデルではCの初期値は1.0です。\n",
    "    \n",
    "モジュールは`LinearSVC`を利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 線形SVMとロジスティック回帰でのCの値の変動による正解率の変動の違いをグラフにしてみましょう。\n",
    "- Cの値の候補であるC_listが渡されますので、線形SVMとロジスティック回帰のモデルをそれぞれ構築し、サブプロットを用いて2つのグラフに出力してください。\n",
    "- 1つのグラフには教師用データに対する正解率とテスト用データに対する正解率の2つのグラフが出力されるようにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cの値の範囲を設定(今回は1e-5,1e-4,1e-3,0.01,0.1,1,10,100,1000,10000)\n",
    "C_list = [10 ** i for i in range(-5, 5)]\n",
    "\n",
    "# グラフ描画用の空リストを用意\n",
    "svm_train_accuracy = []\n",
    "svm_test_accuracy = []\n",
    "log_train_accuracy = []\n",
    "log_test_accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "for C in C_list:\n",
    "    # 線形SVMのモデルを構築してください\n",
    "    model1 = \n",
    "    model1.fit(train_X, train_y)\n",
    "    svm_train_accuracy.append(model1.score(train_X, train_y))\n",
    "    svm_test_accuracy.append(model1.score(test_X, test_y))\n",
    "    \n",
    "    # ロジスティック回帰のモデルを構築してください\n",
    "    model2 = \n",
    "    model2.fit(train_X, train_y)\n",
    "    log_train_accuracy.append(model2.score(train_X, train_y))\n",
    "    log_test_accuracy.append(model2.score(test_X, test_y))\n",
    "    \n",
    "# グラフの準備\n",
    "# semilogx()はxのスケールを10のx乗のスケールに変更する\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.grid(True)\n",
    "ax.set_title(\"SVM\")\n",
    "ax.set_xlabel(\"C\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.semilogx(C_list, svm_train_accuracy, label=\"accuracy of train_data\")\n",
    "ax.semilogx(C_list, svm_test_accuracy, label=\"accuracy of test_data\")\n",
    "ax.legend()\n",
    "ax.plot()\n",
    "plt.show()\n",
    "fig2 =plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "ax2.grid(True)\n",
    "ax2.set_title(\"LogisticRegression\")\n",
    "ax2.set_xlabel(\"C\")\n",
    "ax2.set_ylabel(\"accuracy\")\n",
    "ax2.semilogx(C_list, log_train_accuracy, label=\"accuracy of train_data\")\n",
    "ax2.semilogx(C_list, log_test_accuracy, label=\"accuracy of test_data\")\n",
    "ax2.legend()\n",
    "ax2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってC_listの中身を取り出しましょう。\n",
    "- Cの値のチューニングの仕方は以下の通りです。  \n",
    "`model = LinearSVC(C=1.0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cの値の範囲を設定(今回は1e-5,1e-4,1e-3,0.01,0.1,1,10,100,1000,10000)\n",
    "C_list = [10 ** i for i in range(-5, 5)]\n",
    "\n",
    "# グラフ描画用の空リストを用意\n",
    "svm_train_accuracy = []\n",
    "svm_test_accuracy = []\n",
    "log_train_accuracy = []\n",
    "log_test_accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "for C in C_list:\n",
    "    # 線形SVMのモデルを構築してください\n",
    "    model1 = LinearSVC(C=C, random_state=42)\n",
    "    model1.fit(train_X, train_y)\n",
    "    svm_train_accuracy.append(model1.score(train_X, train_y))\n",
    "    svm_test_accuracy.append(model1.score(test_X, test_y))\n",
    "    \n",
    "    # ロジスティック回帰のモデルを構築してください\n",
    "    model2 = LogisticRegression(C=C, random_state=42)\n",
    "    model2.fit(train_X, train_y)\n",
    "    log_train_accuracy.append(model2.score(train_X, train_y))\n",
    "    log_test_accuracy.append(model2.score(test_X, test_y))\n",
    "    \n",
    "# グラフの準備\n",
    "# semilogx()はxのスケールを10のx乗のスケールに変更する\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.grid(True)\n",
    "ax.set_title(\"SVM\")\n",
    "ax.set_xlabel(\"C\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.semilogx(C_list, svm_train_accuracy, label=\"accuracy of train_data\")\n",
    "ax.semilogx(C_list, svm_test_accuracy, label=\"accuracy of test_data\")\n",
    "ax.legend()\n",
    "ax.plot()\n",
    "plt.show()\n",
    "fig2 =plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "ax2.grid(True)\n",
    "ax2.set_title(\"LogisticRegression\")\n",
    "ax2.set_xlabel(\"C\")\n",
    "ax2.set_ylabel(\"accuracy\")\n",
    "ax2.semilogx(C_list, log_train_accuracy, label=\"accuracy of train_data\")\n",
    "ax2.semilogx(C_list, log_test_accuracy, label=\"accuracy of test_data\")\n",
    "ax2.legend()\n",
    "ax2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "HyLgq2IoIlf",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.3.2 パラメーター penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "ロジスティック回帰同様に線形SVMにも<b style='color: #AA0000'>penalty</b>のパラメーターがあります。<br>\n",
    "設定できる値も同じく、<b>\"L1\"</b>と<b>\"L2\"</b>です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- データの要素がA,B,C,Dの4種類であり、ラベルがDである時、次のペナルティに関する説明のうち正しいものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. A,B,Cの間に相関性がない時ペナルティはL1を選ぶべきである。\n",
    "1. L2ペナルティはデータ同士の依存性を高める。\n",
    "1. B=2A,C=Aの関係がある時、L1ペナルティはBとCの重みを減らしAだけでモデルに説明させるように働く。\n",
    "1. L2ペナルティはDに対してA,B,Cのいずれかが関連性が高い場合、その関連性を失わせる方向に働く。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- L1ペナルティは主成分を抽出する働きがあります。\n",
    "- L2ペナルティは特定の相関性を見ず、データ全体の関係性を用いてモデルを説明しようとします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "B=2A,C=Aの関係がある時、L1ペナルティはBとCの重みを減らしAだけでモデルに説明させるように働く。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "ByPg93LjLgf",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.3.3 パラメーター multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>multi_class</b>は多項分類を行う際に<b>モデルがどういった動作を行うかということを決めるパラメーター</b>です。<br>\n",
    "線形SVMでは「`ovr`」、「`crammer_singer`」の2つの値が用意されています。<br>\n",
    "基本的には`ovr`の方が動作が軽く結果が良いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- multi_classに関する説明のうち正しいものを選択してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 多クラス分類を行う際に値が設定されていると正解率が向上する。\n",
    "1. ovrとcrammer_singerではcrammer_singerのほうが正解率がいい。\n",
    "1. Yes or Noの二値分類ではこの値は無視される。\n",
    "1. LinearSVCでは意味のないパラメーターである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 線形SVMではmulti_classの初期値はovrです。\n",
    "- 二値分類の場合このパラメーターを設定する必要はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "Yes or Noの二値分類ではこの値は無視される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rkdeqn8o8gz",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.3.4 パラメーター random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b>結果の固定</b>(乱数の固定)に用いられる<b style='color: #AA0000'>random_state</b>ですが、SVMに関してはサポートベクターの決定にも関わります。<br>\n",
    "最終的に学習する境界線はほぼ同じになるものの、わずかながら差異が出ることに留意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- random_stateを固定する時に正しい文章を以下の選択肢から選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 結果を固定するために、任意の数値で固定する。\n",
    "1. モデルの学習時にはrandom_stateは特定の値にしなければならない。\n",
    "1. random_stateの値はそのまま乱数の値として用いられる。\n",
    "1. random_stateは調整の必要がない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- random_stateは値が違うと差異が生じる場合があります。特にデータ同士が密接せず散らばっている場合はサポートベクターの選択が変わるため境界線に大きく影響します。\n",
    "- random_stateの値が同じ値であれば、同じ操作をする限りモデルは同じ予測結果を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "結果を固定するために、任意の数値で固定する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "SyeQ_AQWl-f"
   },
   "source": [
    "## 2.4 非線形SVMのハイパーパラメーター"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "BJYlc3LsLxf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "###  2.4.1 パラメーター C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "線形分離可能でないデータを扱う場合SVMの<b>SVC</b>というモジュールを使います。<br>\n",
    "SVCでもロジティック回帰、SVMと同様にパラメーターCが存在します。<br>\n",
    "\n",
    "非線形SVMではCを調整して<b style='color:#AA0000'>ペナルティ</b>を与えます。ペナルティは、学習時に分類の誤りをどの程度許容するかを制御します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- Cの値が変化することによってどのくらいモデルの正解率が変わるかをグラフで確認しましょう。\n",
    "- Cの値の候補が入っているリストC_listを用いて教師用データの正解率とテスト用データの正解率をプロットしたグラフをmatplotlibを用いてグラフ化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "X, y = make_gaussian_quantiles(n_samples=1250, n_features=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cの値の範囲を設定(今回は1e-5,1e-4,1e-3,0.01,0.1,1,10,100,1000,10000)\n",
    "C_list = [10 ** i for i in range(-5, 5)]\n",
    "\n",
    "# グラフ描画用の空リストを用意\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "for C in C_list:\n",
    "    model = \n",
    "    model.fit(train_X, train_y)\n",
    "    train_accuracy.append(model.score(train_X, train_y))\n",
    "    test_accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフの準備\n",
    "# semilogx()はxのスケールを10のx乗のスケールに変更する\n",
    "plt.semilogx(C_list, train_accuracy, label=\"accuracy of train_data\")\n",
    "plt.semilogx(C_list, test_accuracy, label=\"accuracy of test_data\")\n",
    "plt.title(\"accuracy with changing C\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- for文を使ってC_listに納められているCの値を取り出し、モデルに学習させましょう。\n",
    "- 非線形SVMのCの値を調整するにはモデルの構築時に次のように引数にCの値を渡します。  \n",
    "`model = SVC(C=1.0, random_state=42)`\n",
    "- 教師データ、テスト用データそれぞれの正解率をそれぞれ`train_accuracy`,`test_accuracy`というリストに入れましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "X, y = make_gaussian_quantiles(n_samples=1250, n_features=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cの値の範囲を設定(今回は1e-5,1e-4,1e-3,0.01,0.1,1,10,100,1000,10000)\n",
    "C_list = [10 ** i for i in range(-5, 5)]\n",
    "\n",
    "# グラフ描画用の空リストを用意\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "for C in C_list:\n",
    "    model = SVC(C=C)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_accuracy.append(model.score(train_X, train_y))\n",
    "    test_accuracy.append(model.score(test_X, test_y))\n",
    "\n",
    "# グラフの準備\n",
    "# semilogx()はxのスケールを10のx乗のスケールに変更する\n",
    "plt.semilogx(C_list, train_accuracy, label=\"accuracy of train_data\")\n",
    "plt.semilogx(C_list, test_accuracy, label=\"accuracy of test_data\")\n",
    "plt.title(\"accuracy with changing C\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "r1ql938j8lM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.4.2 パラメーター kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "パラメーター<b style='color: #AA0000'>kernel</b>は非線形SVMの中でも特に重要なパラメーターであり、受け取ったデータを操作して<b>分類しやすい形</b>にするための関数を定義するパラメーターです。\n",
    "    \n",
    "`linear`、`rbf`、`poly`、`sigmoid`、`precomputed`の5つを値としてとることができます。デフォルトは`rbf`です。\n",
    "\n",
    "`linear`は線形SVMであり、LinearSVCとほぼ同じです。特殊な理由がない限りはLinearSVCを使いましょう。\n",
    "\n",
    "`rbf`、`poly`は立体投影のようなものです。rbfは他のものに比べ比較的高い正解率が出ることが多いので通常はデフォルトであるrbfを使用します。\n",
    "\n",
    "`precomputed`はデータが前処理によってすでに整形済みの場合に用います。\n",
    "\n",
    "`sigmoid`はロジスティック回帰モデルと同じ処理を行います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- kernelの値に関して、正しい説明はどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. linearは線形カーネルであり、LinearSVCよりも良いチューニングがされている。\n",
    "1. rbfは比較的高い正解率を出すことができる。\n",
    "1. precomputedはどのようなデータに対してでも用いることができる。\n",
    "1. sigmoidはロジスティック回帰モデルそのものである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- LinearSVCとSVC(kernel=\"linear\")では特別に定義されているLinearSVCの方が優れています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "rbfは比較的高い正解率を出すことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "ByslqnUiUgM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.4.3 パラメーター decision_function_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>decision_function_shape</b>はSVCにおける<b>multi_class</b>パラメーターのようなものです。\n",
    "\n",
    "`ovo`、`ovr`の2つの値が用意されています。\n",
    "    \n",
    "`ovo`はクラス同士のペアを作り、そのペアでの2項分類を行い多数決で属するクラスを決定するという考え方です。\n",
    "    \n",
    "`ovr`は一つのクラスとそれ以外という分類を行い多数決で属するクラスを決定します。\n",
    "    \n",
    "`ovo`の方は計算量が多くデータの量の増大によっては動作が重くなることが考えられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- `decision_function_shape`に関する次の説明のうち正しいのはどれでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. ovrは他のクラスとの1対1の分類器を作成し、総当たりでクラスを決定する方法である。\n",
    "1. ovoは計算量が少なく実行速度も速くなる傾向がある。\n",
    "1. ovrは線形分離可能なデータに強い。\n",
    "1. ovoとovrではovoの方がデータが増えた時の実行時間の増加量が大きい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- ovoはone vs oneの略で各クラス同士の総当たりの分類器を作成し予測します。\n",
    "- ovrはone vs restの略で各クラスの自身とそれ以外を分類する分類器を作成し予測します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "ovoとovrではovoの方がデータが増えた時の実行時間の増加量が大きい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rJnxqnIjLlG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.4.4 パラメーター random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>random_state</b>はデータの処理順に関係するパラメーターです。\n",
    "予測結果を再現するために、学習の段階では固定することを推奨します。\n",
    "    \n",
    "機械学習を実際に行う時には乱数を生成するための生成器を指定する方法があります。\n",
    "生成器を指定する場合のコードは以下の通りです。\n",
    "    \n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 乱数生成器を構築\n",
    "random_state = np.random.RandomState()\n",
    "\n",
    "# 乱数生成器をrandom_stateに指定したSVMモデルを構築\n",
    "model = SVC(random_state=random_state)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 非線形SVMモデルのパラメーター`random_state`に乱数生成器を渡してモデルに学習をさせてください。\n",
    "- テスト用データに対する正解率を`print関数`を用いて、出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "# 乱数生成器の構築をしてください\n",
    "random_state = \n",
    "\n",
    "# モデルの構築をしてください\n",
    "model = \n",
    "\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# テストデータに対する正解率を出力\n",
    "print(model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 乱数生成器の構築は、`np.random.RandomState()`で構築できます。\n",
    "- 非線形SVMのモデルは`SVC()`で構築できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 以下にコードを書いてください。\n",
    "# 乱数生成器の構築をしてください\n",
    "random_state = np.random.RandomState()\n",
    "\n",
    "# モデルの構築をしてください\n",
    "model = SVC(random_state=random_state)\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# テストデータに対する正解率を出力\n",
    "print(model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 2.5 まとめ問題(提出不要)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "このチャプターの復習をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコメントアウトの処理をしてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "kernel_list = ['linear','rbf','poly','sigmoid']\n",
    "\n",
    "# モデルの構築\n",
    "for i in kernel_list:\n",
    "    model = \n",
    "    # モデルの学習\n",
    "    \n",
    "    # テストデータに対する正解率を出力\n",
    "    print(i)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "SVMのハイパーパラメータ Cの実装問題を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, n_features=4, n_informative=2, n_redundant=2, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "kernel_list = ['linear','rbf','poly','sigmoid']\n",
    "\n",
    "# モデルの構築\n",
    "for i in kernel_list:\n",
    "    model = SVC(kernel= i ,random_state=42)\n",
    "    # モデルの学習\n",
    "    model.fit(train_X, train_y)\n",
    "    # テストデータに対する正解率を出力\n",
    "    print(i)\n",
    "    print(model.score(test_X, test_y))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "- 分類問題において重要なSVMのパラメータ操作について、意味をしっかり理解しておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "id": "table",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}