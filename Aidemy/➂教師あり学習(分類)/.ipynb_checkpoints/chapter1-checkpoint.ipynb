{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()で可視化されない人はこのセルを実行してください。\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "rJFf_RmZxZf",
    "id": "chapter_name"
   },
   "source": [
    "# 教師あり学習（分類）の基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[1.1 教師あり学習（分類）を知る](#1.1-教師あり学習（分類）を知る)**\n",
    "    - **[1.1.1 「分類」とは](#1.1.1-「分類」とは)**\n",
    "    - **[1.1.2 二項分類と多項分類](#1.1.2-二項分類と多項分類)**\n",
    "    - **[1.1.3 分類の流れ](#1.1.3-分類の流れ)**\n",
    "    - **[1.1.4 データを用意する](#1.1.4-データを用意する)**\n",
    "    - **[1.1.5 学習と予測](#1.1.5-学習と予測)**\n",
    "<br><br>\n",
    "- **[1.2 主な手法の紹介](#1.2-主な手法の紹介)**\n",
    "    - **[1.2.1 ロジスティック回帰](#1.2.1-ロジスティック回帰)**\n",
    "    - **[1.2.2 線形SVM](#1.2.2-線形SVM)**\n",
    "    - **[1.2.3 非線形SVM](#1.2.3-非線形SVM)**\n",
    "    - **[1.2.4 決定木](#1.2.4-決定木)**\n",
    "    - **[1.2.5 ランダムフォレスト](#1.2.5-ランダムフォレスト)**\n",
    "    - **[1.2.6 k-NN](#1.2.6-k-NN)**\n",
    "<br><br>\n",
    "- **[1.3 まとめ問題(提出不要)](#1.3-まとめ問題(提出不要))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "r15zdCX-eWf"
   },
   "source": [
    "## 1.1 教師あり学習（分類）を知る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "r1452LsUlG",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.1 「分類」とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "今回の講座の一部は以下の参考文献を元に製作されています。実装をメインに学習をしていきますが、理論的な部分についてさらに詳しく学びたいという方は、以下を読むと良いでしょう。<br>\n",
    "<a href=\"https://book.impress.co.jp/books/1117101099\" target=\"_blank\">[Python機械学習プログラミング 達人データサイエンティストによる理論と実践]</a>\n",
    "\n",
    "機械学習は主に3つの分野に分かれます。\n",
    "\n",
    "- <b style='color: #AA0000'>教師あり学習</b><br>\n",
    "正解ラベル付きのトレーニングデータからモデルを学習し、未知のデータに対して予測を行います。教師あり学習は以下の２つに分類されます。<br>\n",
    "1. 分類問題<br>\n",
    "カテゴリ別に分けてあるデータを学習し、未知のデータのカテゴリ(離散値)を予測します。\n",
    "<b>このコンテンツではこの分類問題に対するアルゴリズムの理解や簡単な問題の実装を行います。</b>実践的な応用例として、メールのスパム判定などが挙げられます。<br>\n",
    "1. 回帰問題(<a href='https://aidemy.net/courses/5010' target='_blank'>教師あり学習(回帰)</a>)<br>\n",
    "分類問題と違って、こちらは連続値を予測します。株価の予測などはこちらに分類されます。<br><br>\n",
    "\n",
    "- <b style='color: #AA0000'>教師なし学習</b>(<a href='https://aidemy.net/courses/5030' target='_blank'>教師なし学習</a>)<br>\n",
    "正解ラベルのついていないデータや構造が不明なデータに対し、データの構造や関係性を機械が見出すことを指します。  例として、小売店の顧客の傾向やクラスタリングなどが挙げられます。<br><br>\n",
    "\n",
    "- <b style='color: #AA0000'>強化学習</b><br>\n",
    "環境とのやりとりに基づいて性能を改善することを目的とします。行動に対して報酬を設定し、状態に応じて目標の利益を得られる行動を取るように学習させます。\n",
    "例として、囲碁などの対戦型AIなどがあります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のうち機械学習の「分類」として扱われる事例はどれでしょうか。選択してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 株価の予測\n",
    "1. メールのスパム判定\n",
    "1. 対戦型ゲームのAI\n",
    "1. 上記の全て"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 教師あり学習はデータとラベルの関係性からデータのラベルを予測します。\n",
    "- 回帰は主に数値を、分類はデータがどこに属するかを予測します。\n",
    "- 教師なし学習はデータの構造やデータ同士の関連性を調べます。\n",
    "- 強化学習は学習時に自身が達成する目標を定めそのために必要な行動を最適化していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "メールのスパム判定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "BJrc2IoUgG",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.2 二項分類と多項分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "分類問題は、大まかに<b style='color: #AA0000'>二項分類</b>と <b style='color: #AA0000'>多項分類</b>の問題に分けられます。\n",
    "\n",
    "- <b>二項分類</b>（二値分類、２クラス分類とも言います）  \n",
    "    分類するカテゴリー（クラスといいます）が２つの分類問題のことです。どちらか一方のグループに「属している/いない」のみで識別できます。また、直線でクラス間を識別できる場合は<b>線形分類</b>といい、そうでない場合は<b>非線形分類</b>といいます。\n",
    "\n",
    "\n",
    "- <b>多項分類</b>（多クラス分類とも言います）  \n",
    "    クラスが３つ以上の分類問題のことです。これはどれか一つのグループに「属している/いない」だけでは識別ができない上、単に直線では識別できない場合が多いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "以下の散布図において青と橙のデータを教師データとして学習し、どちらに属するかを分類する問題は何と言うでしょうか。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/5020_classification/classification_chap1_10.png\">\n",
    "\n",
    "**<center>図1.1.2-1 分類</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. 二項分類（線形）\n",
    "1. 二項分類（非線型）\n",
    "1. 多クラス分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- クラス数、直線で識別できそうかに注目しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "二項分類（線形）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rkU53Li8xG",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.3 分類の流れ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "機械学習は以下に示すような一連の流れがあります。\n",
    "\n",
    "1.<b>データの前処理</b>\n",
    "  - データの整形、操作\n",
    " \n",
    "\n",
    "2.<b>アルゴリズムの選択</b>\n",
    "  - アルゴリズムを選択し、モデルの作成\n",
    " \n",
    "3.<b>モデルの学習</b>\n",
    "  - チューニングをするハイパーパラメーターの選択\n",
    "  - パラメーターのチューニング\n",
    "\n",
    "4.<b>モデルによる予測（推論)</b>\n",
    "  - 未知のデータを使ってモデルの精度検証\n",
    "  - WEBサービスなどに組み込み、AIモデルを実運用\n",
    " \n",
    "今回扱う「教師あり学習（分類）」モデルでは、「2. アルゴリズムの選択」の部分で様々な「分類アルゴリズム」を選択することになります。開発の現場では、学習データや目的によって、最適の分類アルゴリズムを選択してモデルを作成し、最大の性能を出すようチューニングすることが求められます。\n",
    "\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/153190785150794.PNG\" width=800>\n",
    "\n",
    "<b><center>図1.1.3-1 分類問題</center></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次の文章を機械学習の流れに沿って並べ替えた時の順番を以下の選択肢から選んでください。\n",
    "    1. モデルによる予測\n",
    "    1. モデルの選択\n",
    "    1. データの前処理\n",
    "    1. モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 1 -> 4 -> 2 -> 3\n",
    "- 1 -> 2 -> 3 -> 4\n",
    "- 3 -> 2 -> 4 -> 1\n",
    "- 2 -> 3 -> 4 -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- モデルは学習を行ったのちに予測を行います。\n",
    "- データの前処理はモデル選択より前に行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "3 -> 2 -> 4 -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "SJwc28s8ez",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.4 データを用意する方法(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "様々な分類の手法について実際にコードを動かして学ぶ際に、分類ができそうなデータを用意する必要があります。<br>\n",
    "実用レベルでは実際に測定された何かしらの値を入手し、整形する段階が必要になりますが、今回はその部分は省き、練習用に架空の分類用データを自分で作成する方法や、サンプルデータの取得方法を紹介します。\n",
    "\n",
    "分類に適した架空のデータを作成するには、scikit-learn.datasetsモジュールの `make_classification()`を使います。\n",
    "教師あり学習による分類では、データとそのデータがどのクラスに属しているかを表すラベルが必要です。  \n",
    "`make_classification()`を用いれば任意のデータ数、ラベルの種類を引数で設定することが出来ます。\n",
    "\n",
    "```python\n",
    "# モジュールのimport\n",
    "from sklearn.datasets import make_classification\n",
    "# データX, ラベルyの生成\n",
    "X, y = make_classification(n_samples=XX, n_classes=XX, n_features=XX, n_redundant=XX, random_state=XX)\n",
    "```\n",
    "上記関数の各引数は以下のとおりです。\n",
    "\n",
    "- n_samples<br>\n",
    "    用意するデータの個数\n",
    "- n_classes<br>\n",
    "    クラス数。指定しないと値は2になります\n",
    "- n_features<br>\n",
    "    データの特徴量の個数\n",
    "- n_redundant<br>\n",
    "    分類に不要な特徴量（余分な特徴量）の個数\n",
    "- random_state<br>\n",
    "    乱数のシード（乱数のパターンを決定する要素）\n",
    "\n",
    "\n",
    "他にも引数はありますが、このコンテンツではこれらを定義したデータを作成していきます。  \n",
    "また、データがどのクラスに属しているかを示す「ラベル(y)」が用意されますが、基本的に整数値によってラベルを用意します。  \n",
    "例えば二項分類であれば各データのラベルは「0」または「1」になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 特徴量2, 不要な特徴量は無い二項分類用データXとそのラベルyを50個作成してください\n",
    "- その際の乱数のシードは0としてください\n",
    "- `y=0`となるXの座標を青、`y=1`となるXの座標を赤くプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# モジュールのimport\n",
    "from sklearn.datasets import make_classification\n",
    "# プロット用モジュール\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# データX, ラベルyを生成\n",
    "X, y = \n",
    "\n",
    "\n",
    "# データの色付け、プロット\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"bwr\"), alpha=0.7)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- make_classification関数はXとyを同時に返します\n",
    "- 二項分類のためクラス数は2です"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# モジュールのimport\n",
    "from sklearn.datasets import make_classification\n",
    "# プロット用モジュール\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# データX, ラベルyを生成\n",
    "X, y = make_classification(n_samples=50, n_features=2,\n",
    "                           n_redundant=0, random_state=0)\n",
    "\n",
    "# データの色付け、プロット\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"bwr\"), alpha=0.7)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rkEPkJ3Qm",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.5 データを用意する方法(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "このchapterでは、教師あり学習の分類におけるいくつかの学習方法を学びます。scikit-learnライブラリは主に、分類アルゴリズムの実装をメインに使用されます。しかしscikit-learnライブラリにはこれらだけでなく、データの前処理や、モデルの調整、評価を行うための関数も用意されています。また、アルゴリズムの実験やテスト用にいくつかのデータセットが用意されており、モジュールを指定することでデータを呼び出すことが出来ます。ここではその１つであるIrisデータの取得方法を紹介します。\n",
    "\n",
    "Irisデータとは150個のアヤメ(花の一種)のサンプルの「がく片の長さ」「がく片の幅」「花びらの長さ」「花びらの幅」の４つの特徴量(単位はcm)と、3種の品種(0~2)が格納されています。ここでは、データの可視化のために特徴量を「がくの長さ」「花びらの長さ」の２つだけを使用していきます。\n",
    "\n",
    "Irisデータのイメージ図\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531918623552119.PNG\">\n",
    "\n",
    "<b><center>図1.1.5-1 特徴量</center></b>\n",
    "※値は正しい値ではありません\n",
    "\n",
    "```python\n",
    "# scikit-learnライブラリdetasetモジュールのimport\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# データを取得\n",
    "iris = datasets.load_iris()\n",
    "# irisの0列目と2列目を格納\n",
    "X = iris.data[:, [0, 2]]\n",
    "# irisのクラスラベルを格納\n",
    "y = iris.target\n",
    "```\n",
    "\n",
    "また、トレーニングされたモデルの性能を未知のデータで評価するために、データセットをさらにトレーニングデータとテストデータに分割します。\n",
    "以下のように、scikit-learnの`model_selection`モジュールの`train_test_split()`を使用して、X配列とy配列を30%のテストデータと70%のトレーニングデータにランダムに分割しています。\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "このchapterにおいては、このIrisデータを用いて、学習アルゴリズムの実装を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- scikit-learnライブラリから、Irisデータを取得し、「がくの長さ」「花びらの長さ」の２つの特徴量を`X`に、クラスラベルを`y`に格納してください。\n",
    "- がくの長さを横軸に、花びらの長さを縦軸にプロットできていることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# データを取得してください\n",
    "iris = \n",
    "# irisの0列目と2列目を格納してください\n",
    "X = \n",
    "# irisのクラスラベルを格納してください\n",
    "y = \n",
    "\n",
    "# データの色付け、プロット\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=0.7)\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- make_classification関数はXとyを同時に返します\n",
    "- 二項分類のためクラス数は2です"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# データを取得してください\n",
    "iris = datasets.load_iris()\n",
    "# irisの0列目と2列目を格納してください\n",
    "X = iris.data[:, [0, 2]]\n",
    "# irisのクラスラベルを格納してください\n",
    "y = iris.target\n",
    "\n",
    "# データの色付け、プロット\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=0.7)\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "Bku93Ij8xf",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 15
   },
   "source": [
    "### 1.1.6 学習と予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "機械学習において、アルゴリズムは複数存在します。アルゴリズムに従い教師データから学習を行い、ラベルを予測するまでの一連の流れの概形のことを<b>モデル</b>といいます。\n",
    "\n",
    "機械学習のモデルを全て自分で実装するのは大変ですが、Pythonには機械学習に特化したライブラリがたくさん存在します。  その中でもscikit-learnは機械学習のモデルがあらかじめ用意されたライブラリです。<br>\n",
    "\n",
    "さて、まずは架空のモデルClassifierを例にした使い方を見てみましょう。\n",
    "\n",
    "```python\n",
    "# モジュールのインポート\n",
    "# モデルごとに別のモジュールを参照する(以下例)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# モデルの構築\n",
    "model = Classifier()\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "# モデルによるデータの予測\n",
    "model.predict(test_X)\n",
    "\n",
    "# モデルの正解率\n",
    "# 正解率は (モデルの予測した分類と実際の分類が一致したデータの数) ÷ (データの総数) で算出されます\n",
    "model.score(test_X, test_y)\n",
    "```\n",
    "\n",
    "実際の機械学習のコードを書く際には、`Classifier()`の部分を実際のモデルと差し替えることになります。\n",
    "scikit-learnを利用することによって、以上のようにかなりシンプルに機械学習を実践できるのが魅力です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- データ`train_X`、`train_y`を使って用意したモデルに学習させてみましょう。\n",
    "- また、`test_X`データに対して予測を行い、結果を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(n_samples=100, n_features=2,\n",
    "                           n_redundant=0, random_state=42)\n",
    "# データを学習に使う分と評価の分に分ける\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させてください\n",
    "\n",
    "\n",
    "# test_Xに対するモデルの分類予測結果を格納してください\n",
    "pred_y = \n",
    "\n",
    "print(\"予測:\"+ str(pred_y))\n",
    "print(\"実際:\"+ str(test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `fit`メソッドと`predict`メソッドを使います。\n",
    "- 予測結果は直接出力しても変数に代入してから出力しても構いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(n_samples=100, n_features=2,\n",
    "                           n_redundant=0, random_state=42)\n",
    "# データを学習に使う分と評価の分に分ける\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させる\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_Xに対するモデルの分類予測結果\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print(\"予測:\"+ str(pred_y))\n",
    "print(\"実際:\"+ str(test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "r1if_AmbxWG"
   },
   "source": [
    "## 1.2 主な手法の紹介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "Bkt5hIoIlG",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.1 ロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "先ほど作ったデータをグラフにしたものからモデルを学習していきましょう。\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531852179094452.png\" width=\"500px\">\n",
    "\n",
    "<b><center>図1.2.1-1 ロジスティック回帰</center></b>\n",
    "\n",
    "３色で色分けされた点がグラフ上に描画されていますね。\n",
    "    \n",
    "上のグラフは、色を識別するための直線を作ることができそうです。\n",
    "    \n",
    "このように<b>直線</b>でデータのカテゴリーのグループに分けることができるデータを<b>線形分離可能な</b>データと呼びます。\n",
    "    \n",
    "<b style='color: #AA0000'>ロジスティック回帰</b>は線形分離可能なデータの境界線を学習によって見つけてデータの分類を行なう手法です。  \n",
    "    \n",
    "特徴としては境界線が<b>直線</b>になることです。そのため、二項分類などクラスの少ないデータに用いられます。<br>\n",
    "また、データがクラスに分類される確率も計算することが可能です。これらの特徴から主に「天気予報の降水確率」など、分類される確率を知りたい時に用いられます。\n",
    "    \n",
    "欠点としてはトレーニングデータが<b>線形分離可能でないと分類ができない</b>ということです。また高次元の疎なデータには適しません。<br>\n",
    "また、トレーニングデータから学習した境界線はクラスの端にあるデータのすぐそばを通るようになるため、一般化した境界線になりにくい（汎化能力が低い）ことも欠点です。\n",
    "\n",
    "ロジスティック回帰モデルはscikit-learnライブラリのlinear_modelサブモジュール内に`LogisticRegression()`として定義されています。  \n",
    "ロジスティック回帰モデルを使って学習する場合、次のようなコードを書いてモデルを呼び出します。\n",
    "    \n",
    "```Python\n",
    "# パッケージからモデルを呼び出す\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# モデルを構築する\n",
    "model = LogisticRegression()\n",
    "\n",
    "# モデルに学習させる\n",
    "# train_data_detailはデータのカテゴリーを予測するために使う情報をまとめたもの\n",
    "# train_data_labelはデータの属するクラスのラベル\n",
    "model.fit(train_data_detail, train_data_label)\n",
    "\n",
    "# モデルに予測させる\n",
    "model.predict(data_detail)\n",
    "\n",
    "# モデルの予測結果の正解率\n",
    "model.score(data_detail, data_true_label)\n",
    "```\n",
    "\n",
    "可視化の作業では、学習させたモデルを使用して、グラフ内の細かいプロット点全てに対して予測を行うことで、データをどのように分割しているかを色別に示すことができます。\n",
    "グラフの視覚化にはmatplotlibライブラリを使います。他の学習モデルに関しても、同様の方法で可視化を行い、比較します。\n",
    "\n",
    "```Python\n",
    "# 全データを散布図にプロットし、ラベルごとに色を分ける\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "# グラフの範囲を決定\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# グラフを0.02ごとに区切った時の交点の座標を格納\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "# 全てのxx1,xx2のペアに対して、学習モデルで予測を行う\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "# 座標(xx1, xx2)にZを描画\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "# 範囲、ラベル、タイトル、グリッドを指定\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using LogisticRegression\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "`np.meshgridメソッド`は、`x`, `y`, `...n`の座標行列を作成します。\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# 下図のx\n",
    "x = np.array([1, 2, 3])\n",
    "\n",
    "# 下図のy\n",
    "y = np.array([4, 5])\n",
    "\n",
    "x1, y1 = np.meshgrid(x,y)\n",
    "\n",
    "print(x1)\n",
    "print()\n",
    "print(y1)\n",
    "```\n",
    "```python\n",
    ">>>出力\n",
    "[[1 2 3]\n",
    " [1 2 3]]\n",
    "\n",
    "[[4 4 4]\n",
    " [5 5 5]]\n",
    "```\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1545099825979794.png' width=300>\n",
    "\n",
    "<b><center>図1.2.1-1 np.meshgridのイメージ図</center></b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ロジスティック回帰モデルの構築をしてください。\n",
    "- `train_X`と`train_y`を使ってモデルに学習させてください。\n",
    "- ロジスティック回帰を用いてデータの分類を予測して、変数`pred_y`に代入してください。\n",
    "- 可視化されたグラフをみて、線形分離の様子を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# パッケージをインポート\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline\n",
    "\n",
    "# データを取得\n",
    "iris = datasets.load_iris()\n",
    "# irisの0列目と2列目を格納\n",
    "X = iris.data[:, [0, 2]]\n",
    "# irisのクラスラベルを格納\n",
    "y = iris.target\n",
    "# trainデータ、testデータの分割\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# ロジスティック回帰モデルの構築をしてください\n",
    "model = \n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させてください\n",
    "\n",
    "\n",
    "# test_Xに対するモデルの分類予測結果\n",
    "y_pred = \n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using LogisticRegression\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- モデルの構築と学習が終わった後にグラフの生成を行います。\n",
    "- 境界線のコードは説明文を参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# パッケージをインポート\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline\n",
    "\n",
    "# データを取得\n",
    "iris = datasets.load_iris()\n",
    "# irisの0列目と2列目を格納\n",
    "X = iris.data[:, [0, 2]]\n",
    "# irisのクラスラベルを格納\n",
    "y = iris.target\n",
    "# trainデータ、testデータの分割\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# ロジスティック回帰モデルの構築をしてください\n",
    "model = LogisticRegression()\n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させてください\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_Xに対するモデルの分類予測結果\n",
    "y_pred = model.predict(test_X)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using LogisticRegression\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "HJ55hLoIeM",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.2 線形SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>SVM</b>(サポートベクターマシン)はロジスティック回帰と同じくデータの境界線を見つけることでデータの分類を行なう手法です。\n",
    "その最大の特徴はサポートベクターとよばれるベクトルです。\n",
    "    \n",
    "サポートベクターは、他クラスとの距離が近いデータ群のことです。サポートベクターを基準に、その距離が最も大きくなる位置に境界線を引きます。境界線は、あるクラスから他クラスへの距離が最大になるよう引きます（マージン最大化）。\n",
    "\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1527855492049547.PNG' width=300>\n",
    "\n",
    "<b><center>図1.2.2-1 線形SVM</center></b>\n",
    "\n",
    "SVMは分類する境界線が2クラス間の最も離れた場所に引かれるためロジスティック回帰と比べて一般化されやすく、\n",
    "データの分類予測が向上する傾向が見られます。\n",
    "また、境界線の決定にはサポートベクターのみを考えればよいため、筋道がたちやすいのも特徴です。\n",
    "    \n",
    "欠点としてデータ量が増えると計算量が増えてしまうため、他の手法に比べ学習や<b>予測が遅くなる傾向</b>があるという点が挙げられます。\n",
    "また、ロジスティック回帰と同様に、入力データが線形分離可能（まっすぐ境界面を引ける状態）でない限り正しく分類が行えません。\n",
    "線を真っ直ぐ引き分類するSVMを<b style='color: #AA0000'>線形SVM</b>と言います。\n",
    "\n",
    "線形SVMは、scikit-learnの`LinearSVC()`で実装できます。\n",
    "\n",
    "```Python\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "X, y = make_classification(n_samples=100, n_features=2,\n",
    "                           n_redundant=0, random_state=42)\n",
    "\n",
    "# データを教師データと予測したいデータに分割\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = LinearSVC()\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# 正解率を出力\n",
    "model.score(test_X, test_y)\n",
    "```\n",
    "\n",
    "正解率は`test_X`と`test_y`に対するものです。`train_X`と`train_y`に対する正解率を算出しないので、出力される正解率が100%でもグラフでは誤分類されているものが生じる可能性があります。\n",
    "\n",
    "境界の可視化はロジスティック回帰の方法と同様に以下のコードで実行できます。\n",
    "\n",
    "```Python\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using LinearSVC\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531861142286779.png\">\n",
    "\n",
    "<b><center>図1.2.2-2 出力</center></b>\n",
    "\n",
    "このように境界は直線になっていることがわかります。次の問題でIrisのデータを用いてそれを確かめて見ましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 線形SVMのモデルを構築してください。\n",
    "- 線形SVMを用いてデータの分類を学習してください。\n",
    "- `test_X`と`test_y`を用いてモデルの正解率を出力してください。\n",
    "- 可視化されたグラフをみて、線形分離の様子を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# パッケージをインポート\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# モデルの構築をしてください\n",
    "model = \n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させてください\n",
    "\n",
    "\n",
    "# test_Xとtest_yを用いたモデルの正解率を出力してください\n",
    "print()\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using LinearSVC\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 正解率を出力するには`score`メソッドを用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# パッケージをインポート\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# モデルの構築をしてください\n",
    "model = LinearSVC()\n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させてください\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_Xとtest_yを用いたモデルの正解率を出力してください\n",
    "print(model.score(test_X, test_y))\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using LinearSVC\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "SJj9n8oLgz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.3 非線形SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<a href='https://aidemy.net/courses/5020/exercises/HJ55hLoIeM' target='_blank'>前エクササイズ</a>の線形SVMは筋道が立てやすく、一般性も高い優秀なモデルですが、\n",
    "入力データが線形分離でない限り使えないという欠点を持っていました。\n",
    "\n",
    "非線形SVMはSVMの欠点を取り除くため開発されたモデルです。\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1527857213098549.PNG' width=500>\n",
    "\n",
    "<b><center>図1.2.3-1 非線形SVM</center></b>\n",
    "\n",
    "上記の図のように、カーネル関数と呼ばれる変換式に従って数学的処理を行いデータを操作することで、入力データが線形分離可能な状態となる場合があります。\n",
    "\n",
    "そのような処理を行いSVMを用いるモデルが<b style='color: #AA0000'>非線形SVM</b>です。\n",
    "\n",
    "カーネル関数による操作は複雑なのですが、その操作の計算を行わずともデータの操作後の内積が求められれば分類を行うことが可能なので、<b>カーネルトリック</b>とも呼ばれます。\n",
    "\n",
    "scikit-learnのsvmサブモジュールにある`SVC()`を使います。\n",
    "\n",
    "```Python\n",
    "import matplotlib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの生成\n",
    "# 今回のデータは線形分離可能でないため、他のデータを用意する\n",
    "data, label = make_gaussian_quantiles(n_samples=1000, n_classes=2, n_features=2, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "# 線形分離可能でないデータの分類にはLinearSVCではなくSVCを使う\n",
    "model = SVC()\n",
    "# モデルの学習\n",
    "model.fit(data,label)\n",
    "\n",
    "# 正解率の算出\n",
    "model.score(data,label)\n",
    "```\n",
    "\n",
    "これも同様に出力させると、以下のようになります。\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531861272360942.png\">\n",
    "\n",
    "\n",
    "<b><center>図1.2.3-2 出力</center></b>\n",
    "\n",
    "このように、線形分離できないデータに対して、良い精度を持ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 非線形SVMを用いてデータの分類を学習し、`test_X`と`test_y`を用いてモデルの正解率を出力してください。\n",
    "- また線形SVMでも正解率を出力し、値を比較してください。\n",
    "- 可視化されたグラフを拡大してみて、非線形分離の様子を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# モデルの構築\n",
    "model1 = \n",
    "model2 = \n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させる\n",
    "\n",
    "\n",
    "\n",
    "# 正解率の算出\n",
    "print(\"非線形SVM: {}\".format(model1.score(test_X, test_y)))\n",
    "print(\"線形SVM: {}\".format(model2.score(test_X, test_y)))\n",
    "\n",
    "\n",
    "# 以下可視化の作業です\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "axL.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z1 = model1.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axL.contourf(xx1, xx2, Z1, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axL.set_xlim(xx1.min(), xx1.max())\n",
    "axL.set_ylim(xx2.min(), xx2.max())\n",
    "axL.set_title(\"classification data using SVC\")\n",
    "axL.set_xlabel(\"Sepal length\")\n",
    "axL.set_ylabel(\"Petal length\")\n",
    "axL.grid(True)\n",
    "\n",
    "axR.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z2 = model2.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axR.contourf(xx1, xx2, Z2, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axR.set_xlim(xx1.min(), xx1.max())\n",
    "axR.set_ylim(xx2.min(), xx2.max())\n",
    "axR.set_title(\"classification data using LinearSVC\")\n",
    "axR.set_xlabel(\"Sepal length\")\n",
    "axR.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 線形SVMと非線形SVMは同じモジュールですが違う名前のモデルです。混同しないように注意しましょう。\n",
    "- 値の比較は正解率を並べるだけで良いです。比較結果を算出する必要はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T17:34:33.035814Z",
     "start_time": "2019-01-15T17:34:19.276945Z"
    },
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "# モデルの構築\n",
    "model1 = SVC()\n",
    "model2 = LinearSVC()\n",
    "\n",
    "# train_Xとtrain_yを使ってモデルに学習させる\n",
    "model1.fit(train_X, train_y)\n",
    "model2.fit(train_X, train_y)\n",
    "\n",
    "# 正解率の算出\n",
    "print(\"非線形SVM-score: {}\".format(model1.score(test_X, test_y)))\n",
    "print(\"線形SVM-score: {}\".format(model2.score(test_X, test_y)))\n",
    "\n",
    "\n",
    "# 以下可視化のコードです\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "axL.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z1 = model1.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axL.contourf(xx1, xx2, Z1, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axL.set_xlim(xx1.min(), xx1.max())\n",
    "axL.set_ylim(xx2.min(), xx2.max())\n",
    "axL.set_title(\"classification data using SVC\")\n",
    "axL.set_xlabel(\"Sepal length\")\n",
    "axL.set_ylabel(\"Petal length\")\n",
    "axL.grid(True)\n",
    "\n",
    "axR.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z2 = model2.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axR.contourf(xx1, xx2, Z2, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axR.set_xlim(xx1.min(), xx1.max())\n",
    "axR.set_ylim(xx2.min(), xx2.max())\n",
    "axR.set_title(\"classification data using LinearSVC\")\n",
    "axR.set_xlabel(\"Sepal length\")\n",
    "axR.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "Skh92UiUlz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.4 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>決定木</b>はこれまで紹介したロジスティック回帰やSVMとは違い、<b>データの要素</b>（説明変数）の一つ一つに着目し、その要素内でのある値を境にデータを分割していくことでデータの属するクラスを決定しようとする手法です。\n",
    "    \n",
    "決定木では説明変数の一つ一つが目的変数にどのくらいの影響を与えているのかを見ることができます。\n",
    "分割を繰り返すことで枝分かれしていきますが、先に分割される変数ほど影響力が大きいと捉えることができます。\n",
    "    \n",
    "欠点は線形分離不可能なデータは苦手であること(例えば2次元データでは境界線が斜めに引けない)と、学習が教師データに寄りすぎる(汎化されない)ことです。\n",
    "\n",
    "scikit-learnのtreeサブモジュールにある`DecisionTreeClassifier()`を用います。\n",
    "\n",
    "```Python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# 学習データとテストデータに分ける\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# 正解率の算出\n",
    "model.score(test_X, test_y)\n",
    "```\n",
    "\n",
    "同様の方法で境界を可視化させた結果は以下のようになります。\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531861466620389.png\">\n",
    "\n",
    "<b><center>図1.2.4-1 境界の可視化</center></b>\n",
    "\n",
    "軸に平行な境界が見られることがわかります。これは決定木分類の特徴の１つでもあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 決定木のモデルを構築してください。\n",
    "- モデルを学習させてください。\n",
    "- 決定木を用いてデータの分類を学習し、`test_X`と`test_y`を用いてモデルの正解率を出力してください。\n",
    "- 可視化されたグラフをみて、決定木アルゴリズムによる分離の様子を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください。\n",
    "# モデルの構築をしてください\n",
    "model = \n",
    "\n",
    "# モデルの学習させてください\n",
    "\n",
    "\n",
    "# test_Xとtest_yを用いたモデルの正解率を出力\n",
    "print(model.score(test_X, test_y))\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using DecisionTreeClassifier\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 複数回実行して、境界の性質を観察してみましょう。\n",
    "- モデルの構築は`DecisionTreeClassifier()`で行います。\n",
    "- モデルの学習は`model.fit(train_X, train_y)`で行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください。\n",
    "# モデルの構築をしてください\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# モデルの学習させてください\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_Xとtest_yを用いたモデルの正解率を出力\n",
    "print(model.score(test_X, test_y))\n",
    "\n",
    "# 以下可視化の作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using DecisionTreeClassifier\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "SJp92LoUef",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 20
   },
   "source": [
    "### 1.2.5 ランダムフォレスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>ランダムフォレスト</b>は、前述の決定木の簡易版を複数作り、分類の結果を多数決で決める手法です。<br>\n",
    "複数の簡易分類器を一つの分類器にまとめて学習させる、 <b>アンサンブル学習</b>と呼ばれる学習の種類の一手法でもあります。\n",
    "    \n",
    "決定木では使用する説明変数は全て使用していたのに対し、ランダムフォレストの一つ一つの決定木はランダムに決められた少数の説明変数だけを用いてデータの属するクラスを決定しようとします。\n",
    "その上で複数の簡易決定木から出力されるクラスのうちで最も多かったクラスを結果として出力します。\n",
    "    \n",
    "ランダムフォレストの特徴は決定木と同じように、線形分離可能でない複雑な識別範囲を持つデータ集合の分類が可能な点に加え、複数の分類器を通して多数決により結果を出力するため、外れ値によって予測結果が左右されにくいことが挙げられます。\n",
    "    \n",
    "欠点としては決定木と同じように説明変数の数に対してデータの数が少ないと二分木の分割ができず、予測の精度が下がってしまう点が挙げられます。\n",
    "\n",
    "scikit-learnのensembleサブモジュールにある`RandomForestClassifier()`を用います。\n",
    "\n",
    "```Python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# 学習データとテストデータに分ける\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# 正解率の算出\n",
    "model.score(test_X, test_y)\n",
    "```\n",
    "\n",
    "以上について、境界を可視化した結果は以下のようになります。決定木と似たような境界をしていることがわかります。これは、ランダムフォレストが、決定木アルゴリズムのアンサンブル学習(個々に学習した複数の学習器を融合させて汎化性能を向上させること)をしているためです。\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531861843551795.png\">\n",
    "\n",
    "<b><center>図1.2.5-1 境界の可視化</center></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ランダムフォレストと決定木のモデルを構築してください。\n",
    "- ランダムフォレストを用いてデータの分類を学習し、`test_X`と`test_y`を用いてモデルの正解率を出力してください。\n",
    "- また決定木でも正解率を出力し、値を比較してください。\n",
    "- 可視化されたグラフをみて、決定木とランダムフォレストによる分離方法の様子を比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model1 = \n",
    "model2 = \n",
    "\n",
    "# モデルの学習\n",
    "model1.fit(train_X, train_y)\n",
    "model2.fit(train_X, train_y)\n",
    "\n",
    "# 正解率を算出\n",
    "print(\"ランダムフォレスト: {}\".format(model1.score(test_X, test_y)))\n",
    "print(\"決定木: {}\".format(model2.score(test_X, test_y)))\n",
    "\n",
    "# 以下可視化作業です\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "axL.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z1 = model1.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axL.contourf(xx1, xx2, Z1, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axL.set_xlim(xx1.min(), xx1.max())\n",
    "axL.set_ylim(xx2.min(), xx2.max())\n",
    "axL.set_title(\"classification data using RandomForestClassifier\")\n",
    "axL.set_xlabel(\"Sepal length\")\n",
    "axL.set_ylabel(\"Petal length\")\n",
    "axL.grid(True)\n",
    "\n",
    "axR.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z2 = model2.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axR.contourf(xx1, xx2, Z2, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axR.set_xlim(xx1.min(), xx1.max())\n",
    "axR.set_ylim(xx2.min(), xx2.max())\n",
    "axR.set_title(\"classification data using DecisionTreeClassifier\")\n",
    "axR.set_xlabel(\"Sepal length\")\n",
    "axR.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- ランダムフォレストのモデル構築は、`RandomForestClassifier()`を用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = DecisionTreeClassifier()\n",
    "\n",
    "# モデルの学習\n",
    "model1.fit(train_X, train_y)\n",
    "model2.fit(train_X, train_y)\n",
    "\n",
    "# 正解率を算出\n",
    "print(\"ランダムフォレスト: {}\".format(model1.score(test_X, test_y)))\n",
    "print(\"決定木: {}\".format(model2.score(test_X, test_y)))\n",
    "\n",
    "# 以下可視化作業です\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "axL.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z1 = model1.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axL.contourf(xx1, xx2, Z1, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axL.set_xlim(xx1.min(), xx1.max())\n",
    "axL.set_ylim(xx2.min(), xx2.max())\n",
    "axL.set_title(\"classification data using RandomForestClassifier\")\n",
    "axL.set_xlabel(\"Sepal length\")\n",
    "axL.set_ylabel(\"Petal length\")\n",
    "axL.grid(True)\n",
    "\n",
    "axR.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z2 = model2.predict(\n",
    "    np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "axR.contourf(xx1, xx2, Z2, alpha=0.4,\n",
    "             cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "axR.set_xlim(xx1.min(), xx1.max())\n",
    "axR.set_ylim(xx2.min(), xx2.max())\n",
    "axR.set_title(\"classification data using DecisionTreeClassifier\")\n",
    "axR.set_xlabel(\"Sepal length\")\n",
    "axR.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5020,
    "exerciseId": "rk0cnIo8ef",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 30
   },
   "source": [
    "### 1.2.6 k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>k-NN</b>はk近傍法とも呼ばれ、予測をするデータと類似したデータをいくつか見つけ、多数決により分類結果を決める手法です。<br>\n",
    "怠惰学習と呼ばれる学習の種類の一手法であり、<b>学習コスト</b>（学習にかかる計算量）が0であることが特徴です。\n",
    "    \n",
    "これまで紹介してきた手法とは違い、k-NNは教師データから学習するわけではなく、<b>予測時に教師データを直接参照</b>してラベルを予測します。\n",
    "結果の予測を行う際の手法は以下の通りです。\n",
    "\n",
    "1. 教師データを予測に用いるデータとの類似度で並べ直す。\n",
    "2. 分類器に設定されたk個分のデータを類似度の高い順に参照する。\n",
    "3. 参照された教師データが属するクラスのなかで最も多かったものを予測結果として出力する。\n",
    "    \n",
    "k-NNの特徴としては、前述の通り<b>学習コストが0</b>であること、アルゴリズムとしては比較的単純なものなのですが高い予測精度がでやすいこと、複雑な形の境界線も表現しやすいことが挙げられます。<br>\n",
    "欠点としては、分類器に指定する自然数$k$の個数を増やしすぎると識別範囲の平均化が進み予測精度が下がってしまう点や、予測時に毎回計算を行うため教師データや予測データの量が増えると計算量が増えてしまい、低速なアルゴリズムとなってしまう点が挙げられます。\n",
    "    \n",
    "以下の画像は、$k$の数の違いによる分類過程の様子の違いを表しています。\n",
    "灰色の点は$k=3$の時では水色の点の方が周りに多いため水色の点だと予測されますが、 $k=7$の時では緑色の点の方が多いため緑色の点ではないかという予測に変わります。\n",
    "\n",
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/5020_classification/classification_chap1_30.svg' width=300>\n",
    "\n",
    "<b><center>図1.2.6-1 k-NN</center></b>\n",
    "\n",
    "scikit-learnのサブモジュールneighborsにある`KNeighborsClassifier()`を使います。\n",
    "\n",
    "```Python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# 学習データとテストデータに分ける\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = KNeighborsClassifier()\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# 正解率の算出\n",
    "model.score(test_X, test_y)\n",
    "```\n",
    "\n",
    "このモデルの境界を可視化したものは例えば以下のようになります。\n",
    "\n",
    "<img src=\"https://aidemyexstorage.blob.core.windows.net/aidemycontents/1531862140308725.png\">\n",
    "\n",
    "<b><center>図1.2.6-2 境界の可視化</center></b>\n",
    "\n",
    "比較的滑らかな境界曲線が得られました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- k-NNのモデルを構築してください。\n",
    "- k-NNを用いてデータの分類を学習し、`test_X`と`test_y`を用いてモデルの正解率を出力してください。\n",
    "- 可視化されたグラフをみて、k-NNによる分離の様子を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = \n",
    "\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# 正解率の表示\n",
    "print(model.score(test_X, test_y))\n",
    "\n",
    "# 以下可視化作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using KNeighborsClassifier\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `sklearn.neighbors`にある`KNeighborsClassifier()`を用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# データの生成\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# モデルの構築\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# 正解率の表示\n",
    "print(model.score(test_X, test_y))\n",
    "\n",
    "# 以下可視化作業です\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, marker=\".\",\n",
    "            cmap=matplotlib.cm.get_cmap(name=\"cool\"), alpha=1.0)\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T).reshape((xx1.shape))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.cm.get_cmap(name=\"Wistia\"))\n",
    "plt.xlim(xx1.min(), xx1.max())\n",
    "plt.ylim(xx2.min(), xx2.max())\n",
    "plt.title(\"classification data using KNeighborsClassifier\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Petal length\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 1.3 まとめ問題(提出不要)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "- このチャプターの復習をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコメントアウトの処理を行ってください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# データX, ラベルyを生成してください(samples=1000, features=2,random_state=42)\n",
    "X, y = make_classification()\n",
    "\n",
    "# trainデータ、testデータの分割してください(テストサイズ=0.2,random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split()\n",
    "\n",
    "# モデルを構築してください\n",
    "model_list = {'ロジスティック回帰':  ,\n",
    "                        '線形SVM':  ,\n",
    "                        '非線形SVM':  ,\n",
    "                        '決定木':  ,\n",
    "                        'ランダムフォレスト':  }\n",
    "\n",
    "# for文を使用してモデルの学習、正解率を出力してください\n",
    "for model_name, model in model_list.items():\n",
    "    # モデルの学習\n",
    "    model.fit(train_X,train_y)\n",
    "    print(model_name)\n",
    "    # 正解率の出力\n",
    "    print('正解率:  '+str())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- データを用意する方法(1)(2)を復習して引数の操作を確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# データX, ラベルyを生成してください(samples=1000, features=2,random_state=42)\n",
    "X, y = make_classification(n_samples=1000, n_features=2,\n",
    "                           n_redundant=0, random_state=0)\n",
    "\n",
    "# trainデータ、testデータの分割してください(テストサイズ=0.2,random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルを構築してください\n",
    "model_list = {'ロジスティック回帰':LogisticRegression(),\n",
    "                        '線形SVM':LinearSVC(),\n",
    "                        '非線形SVM':SVC(),\n",
    "                        '決定木':DecisionTreeClassifier(),\n",
    "                        'ランダムフォレスト':RandomForestClassifier()}\n",
    "\n",
    "# for文を使用してモデルの学習、正解率を出力してください\n",
    "for model_name, model in model_list.items():\n",
    "    model.fit(train_X,train_y)\n",
    "    print(model_name)\n",
    "    print('正解率:  '+str(model.score(test_X,test_y)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "- `make_classification()`関数や`train_test_split()関数`の引数の意味をしっかり理解しておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
