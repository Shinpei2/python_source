{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()で可視化されない人はこのセルを実行してください。\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初めの一回だけこのセルを実行してください、データセットをダウンロードして展開します\n",
    "# 一回実行すれば、データセットはダウンロードされたままなので、再起動後等再び実行する必要はありません\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# URLを指定\n",
    "url = \"https://storage.googleapis.com/tutor-contents-dataset/5050_nlp_data.zip\"\n",
    "save_name = url.split('/')[-1]\n",
    "\n",
    "# ダウンロードする\n",
    "mem = urllib.request.urlopen(url).read()\n",
    "\n",
    "# ファイルへ保存\n",
    "with open(save_name, mode='wb') as f:\n",
    "    f.write(mem)\n",
    "\n",
    "# zipファイルをカレントディレクトリに展開する\n",
    "zfile = zipfile.ZipFile(save_name)\n",
    "zfile.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "HJcEuC7Wlbz",
    "id": "chapter_name"
   },
   "source": [
    "# 文章の単語分割と正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[1.1 自然言語処理の基本](#1.1-自然言語処理の基本)**\n",
    "    - **[1.1.1 自然言語処理の概要](#1.1.1-自然言語処理の概要)**\n",
    "    - **[1.1.2 言語による違い](#1.1.2-言語による違い)**\n",
    "<br><br>\n",
    "- **[1.2 文章の単語分割](#1.2-文章の単語分割)**\n",
    "    - **[1.2.1 形態素解析とNgram](#1.2.1-形態素解析とNgram)**\n",
    "    - **[1.2.2 MeCab](#1.2.2-MeCab)**\n",
    "    - **[1.2.3 janome1](#1.2.3-janome1)**\n",
    "    - **[1.2.4 janome2](#1.2.4-janome2)**\n",
    "    - **[1.2.5 split関数](#1.2.5-split関数)**\n",
    "    - **[1.2.6 janome3](#1.2.6-janome3)**\n",
    "    - **[1.2.7 Ngram](#1.2.7-Ngram)**\n",
    "<br><br>\n",
    "- **[1.3 正規化](#1.3-正規化)**\n",
    "    - **[1.3.1 正規化1](#1.3.1-正規化1)**\n",
    "    - **[1.3.2 正規化2](#1.3.2-正規化2)**\n",
    "    - **[1.3.3 正規化3](#1.3.3-正規化3)**\n",
    "    - **[1.3.4 正規表現](#1.3.4-正規表現)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "H1sNu0QZeWM"
   },
   "source": [
    "## 1.1 自然言語処理の基本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "HJOGc2Us8xG",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.1 自然言語処理の概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>自然言語</b>(NL, Natural Language)とは、日本語や英語のような **自然発生的に生まれた言語** のことを指し、プログラミング言語のような人工言語(Artificial Language)とは対比の存在です。\n",
    "\n",
    "<b style='color: #AA0000'>自然言語処理</b>(NLP, Natural Language Processing)とは、人間が日常的に使っている **自然言語をコンピュータに処理させる技術** のことです。  \n",
    "自然言語処理を用いたタスクには、文書分類・機械翻訳・文書要約・質疑応答・対話などがあります。\n",
    "\n",
    "自然言語処理でよく使われるワードとして、以下のようなものがあげられます。\n",
    "> - **トークン**：自然言語を解析する際、文章の最小単位として扱われる文字や文字列のこと。\n",
    "> - **タイプ**：単語の種類を表す用語。\n",
    "> - **文章**：まとまった内容を表す文のこと。自然言語処理では一文を指すことが多い。\n",
    "> - **文書**：複数の文章から成るデータ一件分を指すことが多い。\n",
    "> - **コーパス**：文書または音声データにある種の情報を与えたデータ。\n",
    "> - **シソーラス**：単語の上位/下位関係、部分/全体関係、同義関係、類義関係などによって単語を分類し、体系づけた類語辞典・辞書。\n",
    "> - **形態素**：意味を持つ最小の単位。「食べた」という単語は、2つの形態素「食べ」と「た」に分解できる。\n",
    "> - **単語**：単一または複数の形態素から構成される小さな単位。\n",
    "> - **表層**：原文の記述のこと。\n",
    "> - **原形**：活用する前の記述のこと。\n",
    "> - **特徴**：文章や文書から抽出された情報のこと。\n",
    "> - **辞書**：自然言語処理では、単語のリストを指す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 下の中から自然言語処理が用いられているものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- AppleのSiri\n",
    "- Gunosy\n",
    "- 検索エンジン\n",
    "- 上記のすべて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 自然言語を処理させるものは全て自然言語処理になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 上記のすべて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "HJFMq28o8lM",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.1.2 言語による違い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "文章の意味を機械に理解させるためには、単語分割を行う必要があります。\n",
    "例えば、「私はアイデミーで勉強します。」という文は\n",
    "```\n",
    "　私　|　は　|　アイデミー　｜　で　｜　勉強し　｜　ます　｜\n",
    " 名詞　副助詞　 　名詞　　　格助詞　   動詞　 　助動詞\n",
    "```\n",
    "のように単語の区切りを同定し、その品詞と基本形を上記のように求めることができます。日本語は単語の区切りを同定することが難しいですが、一方で複数の解釈を持つ単語が少ないので品詞や、基本形を求めることは容易です。<br>\n",
    "\n",
    "中国語やタイ語も単語分割が必要な言語です。<br>\n",
    "\n",
    "英語の場合は、\n",
    "```\n",
    "I | study | at | aidemy.\n",
    "名詞　動詞　前置詞　名詞\n",
    "```\n",
    "\n",
    "のように単語の区切りは空白やピリオド等の記号により同定できますが、多くの語が複数の品詞をもつため品詞を同定することは難しいです。<br>\n",
    "以上からわかるように**言語ごとに問題の所在、難しさが異なるのが自然言語処理の特徴**です。\n",
    "\n",
    "\n",
    "以下のようにひらがな表記の時は特に難しいです。\n",
    "```\n",
    "くるま | で | まつ\n",
    "くる | まで | まつ\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下の文章の空欄に入る語句の組み合わせを選んでください。\n",
    "- 日本語や「」は自然言語処理において「」を同定することが難しいです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 「中国語」、「品詞」\n",
    "- 「英語」、「単語の区切り」\n",
    "- 「タイ語」、「単語の区切り」\n",
    "- 「フランス語」、「品詞」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- フランス語は英語と同じくラテン語から派生しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 「タイ語」、「単語の区切り」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "By3NdCX-xbf"
   },
   "source": [
    "## 1.2 文章の単語分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "HyczqnUjUxz",
    "id": "quiz_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.1 形態素解析とNgram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "文章の単語分割の手法は大きく二つ存在し、 <b style='color: #AA0000'>形態素解析</b>と <b style='color: #AA0000'>Ngram</b>があります。<br>\n",
    "<b style='color: #AA0000'>形態素</b>とは **意味を持つ最小の言語単位** のことであり、単語は一つ以上の形態素を持ちます。<br>\n",
    "<b style='color: #AA0000'>形態素解析</b>とは、辞書を利用して形態素に分割し、さらに形態素ごとに品詞などのタグ付け（情報の付与）を行うことを指します。\n",
    "\n",
    "\n",
    "一方で <b style='color: #AA0000'>Ngram</b>とは、 **N文字ごとに単語を切り分ける** 、または **N単語ごとに文章を切り分ける** 解析手法のことです。<br>\n",
    "\n",
    "1文字、あるいは1単語ごとに切り出したものを **モノグラム** 、2文字（単語）ごとに切り出したものを **バイグラム** 、3文字（単語）ごとに切り出したものを **トリグラム** と呼びます。\n",
    "\n",
    "例えば「あいうえお」という文の文字のモノグラム・バイグラム・トリグラムを考えてみると以下のようになります。\n",
    "```\n",
    "モノグラム：{あ, い, う, え, お}\n",
    "バイグラム：{あい, いう, うえ, えお}\n",
    "トリグラム：{あいう, いうえ, うえお}\n",
    "```\n",
    "\n",
    "Ngram は形態素解析のように辞書や文法的な解釈が不要であるため、 **言語に関係なく** 用いることができます。<br>\n",
    "また Ngram は特徴抽出の漏れが発生しにくいメリットがありますが、ノイズが大きくなるデメリットがあります。\n",
    "逆に形態素解析は辞書の性能差が生じてしまう代わりにノイズが少ないです。\n",
    "\n",
    "例えば、「東京都の世界一有名なIT企業」という少し長い文字列について検索する際、バイグラムによって文字列を分割し検索すると「京都」の企業がヒットする可能性が出てしまいます。\n",
    "なぜなら「東京都」の文字バイグラムを列挙すると{東京, 京都}となるからです。  \n",
    "形態素解析を適切に用いるとこのようなことは起こりませんが、性能の高い辞書を用意する必要があります。\n",
    "\n",
    "**＜用語＞**\n",
    "\n",
    "> - **単語分割**：文章を単語に分割すること\n",
    "> - **品詞タグ付け**：単語を品詞に分類して、タグ付けをする処理のこと\n",
    "> - **形態素解析**：形態素への分割と品詞タグ付けの作業をまとめたもの"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下の文章の空欄に当てはまる語句の組み合わせを選んでください。\n",
    "- 形態素解析は「」を用いて「」をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 「辞書」、「文章の分割」\n",
    "- 「ルール」、「文章の分割と品詞の同定」\n",
    "- 「ルール」、「文章の分割」\n",
    "- 「辞書」、「文章の分割と品詞の同定」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 形態素解析は、二つのことをします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 「辞書」、「文章の分割と品詞の同定」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "SJoGc28iUxM",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.2 MeCab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "形態素解析の難しさについてなんとなくイメージが掴めたと思います。「形態素解析なんてできるの？」とお思いかもしれませんが、安心してください。<br>とても優秀なツールが存在します。\n",
    "\n",
    "形態素解析を行うにあたりあらかじめ形態素解析ツールが用意されており、日本語の形態素解析器として代表的なものに<b style='color: #AA0000'>MeCab</b>や<b style='color: #AA0000'>janome</b>などがあります。  \n",
    "\n",
    "MeCabやjanomeは辞書を参考に形態素解析を行います。  \n",
    "ここではMecabの使い方を学習します。以下のMecabを使った形態素解析の実行例を見てください。\n",
    "\n",
    "```python \n",
    "import MeCab\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Owakati\")\n",
    "print(mecab.parse(\"明日は晴れるでしょう。\"))\n",
    "# 出力結果\n",
    "明日 は 晴れる でしょ う 。 \n",
    "```\n",
    "```python\n",
    "mecab = MeCab.Tagger(\"-Ochasen\")\n",
    "print(mecab.parse(\"明日は晴れるでしょう。\"))\n",
    "\n",
    "\"\"\"\n",
    "# 出力結果\n",
    "明日\tアシタ\t明日\t名詞-副詞可能\t\t\n",
    "は\tハ\tは\t助詞-係助詞\t\t\n",
    "晴れる\tハレル\t晴れる\t動詞-自立\t一段\t基本形\n",
    "でしょ\tデショ\tです\t助動詞\t特殊・デス\t未然形\n",
    "う\tウ\tう\t助動詞\t不変化型\t基本形\n",
    "。\t。\t。\t記号-句点\t\t\n",
    "\n",
    "EOS\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**MeCab**では`MeCab.Tagger()`の引数を変更することによりデータの出力形式を変更することができます。<br>\n",
    "例のように、`\"-Owakati\"`を引数とすると単語ごとに分ける**分かち書き**、`\"-Ochasen\"`を引数とすると**形態素解析**を行います。<br>\n",
    "`.parse(\"文章\")`とすることにより引数の文章を指定された形式で出力させることができます。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 説明文の例を参考に「ダックスフンドが歩いている。」という文をMeCabを用いて形態素解析してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "# 形態素解析をしてください\n",
    "mecab = \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- MeCabの「C」は大文字であることに注意しましょう。\n",
    "\n",
    "```python\n",
    "import MeCab\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Ochasen\")\n",
    "print(mecab.parse(\"明日は晴れるでしょう。\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "# 形態素解析をしてください\n",
    "mecab = MeCab.Tagger(\"-Ochasen\")\n",
    "print(mecab.parse(\"ダックスフンドが歩いている。\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "SJ2Gc28jIlM",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 30
   },
   "source": [
    "### 1.2.3 janome (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>janome</b>も有名な日本語の形態素解析器の一つです。\n",
    "\n",
    "janomeの利点としては、MeCabのインストールが面倒なことに対して、パッケージのインストールが容易な点です。<br>\n",
    "janomeは初めに`Tokenizer`をインポートし、`Tokenizer` オブジェクトを **`Tokenizer()`** によって作成します。<br>\n",
    "\n",
    "```python \n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "```\n",
    "`Tokenizer`の`tokenize`メソッドに解析したい文字列渡すことで形態素解析できます。<br>\n",
    "`tokenize`メソッドの返り値はタグ付けされたトークン（`Token`オブジェクト）のリストです。<br>\n",
    "\n",
    "```python \n",
    "\n",
    "#形態素解析\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()  # Tokenizerオブジェクトの作成\n",
    "tokens = tokenizer.tokenize(\"pythonの本を読んだ\")\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "    print()\n",
    "\n",
    "\"\"\"\n",
    "# 出力結果 \n",
    "  python\t名詞,固有名詞,組織,*,*,*,python,*,*\n",
    "  の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
    "  本\t名詞,一般,*,*,*,*,本,ホン,ホン\n",
    "  を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
    "  読ん\t動詞,自立,*,*,五段・マ行,連用タ接続,読む,ヨン,ヨン\n",
    "  だ\t助動詞,*,*,*,特殊・タ,基本形,だ,ダ,ダ\n",
    "\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 説明文を参考に、「明日は晴れるだろうか。」をjanomeで形態素解析をしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# 形態素解析をしてください\n",
    "tokenizer = Tokenizer()\n",
    "tokens = tokenizer.tokenize(\"明日は晴れるだろうか。\")\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "```python\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenizerオブジェクトの作成\n",
    "tokenizer = Tokenizer()\n",
    "tokens = tokenizer.tokenize(\"pythonの本を読んだ\")\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# 形態素解析をしてください\n",
    "tokenizer = Tokenizer()\n",
    "tokens = tokenizer.tokenize(\"明日は晴れるだろうか。\")\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "HkTGq3UsLgz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 20
   },
   "source": [
    "### 1.2.4 janome (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<a href='https://aidemy.net/courses/5050/exercises/SJ2Gc28jIlM' target='_blank'>janome(1)</a>では、形態素解析を行いましたが、`tokenize`メソッドの引数に **`wakati=True`** を指定することにより分かち書きをさせることができます。<br>\n",
    "`wakati=True`にした時の返り値は **分かち書きのリスト** となります。\n",
    "```python\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# 分かち書き\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"pythonの本を読んだ\", wakati=True)\n",
    "print(tokens)\n",
    "# 出力結果\n",
    "[\"python\", \"の\", \"本\", \"を\", \"読ん\", \"だ\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 説明文の例を参考に「すもももももももものうち」をjanomeで分かち書きにして表示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# 分かち書きをしてください\n",
    "t = \n",
    "tokens = \n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "```python\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"pythonの本を読んだ\", wakati=True)\n",
    "print(tokens)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# 分かち書きをしてください\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"すもももももももものうち\", wakati=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "HJAGqh8oLeG",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.2.5 split関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "自然言語処理にあたって文書データ等をダウンロードした際、`\"banana, apple, strawberry\"` のように単語と単語が特殊な文字で区切られていることがよくあります。  \n",
    "そのようなときにPythonの組み込み関数である <b style='color: #AA0000'>split関数</b>関数をよく用いるのでここで説明します。\n",
    "<b style='color: #AA0000'>split関数</b>は、数字・アルファベット・記号などが入り混じった **文字列を、ある規則に従って切り分けてリスト化** してくれる関数です。<br>\n",
    "文字列がスペースや区切り文字`(「,」, 「.」, 「_」など)`によって区切られている時に、 **`文字列.split(\"区切り文字\")`** とすることで空白や区切り文字で区切られたリストを得ることができます。\n",
    "\n",
    "```python\n",
    "fruits = \"banana, apple, strawberry\"\n",
    "print(fruits)  # str\n",
    "print(fruits.split(\",\"))  # list\n",
    "# 出力結果\n",
    "banana, apple, strawberry\n",
    "[\"banana\", \" apple\", \" strawberry\"]\n",
    "```\n",
    "```python\n",
    "fruits = \"banana apple srawberry\"\n",
    "print(fruits)  # str\n",
    "print(fruits.split())  # list\n",
    "# 出力結果\n",
    "banana apple srawberry\n",
    "[\"banana\", \"apple\", \"srawberry\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- `split()`関数を用いて、`['1', '2', '3', '4', '5']`を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "number = \"1,2,3,4,5\"\n",
    "print(number)\n",
    "# [\"1\", \"2\", \"3\", \"4\", \"5\"]を出力してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 区切り文字は「,」\"カンマ\"です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "number = \"1,2,3,4,5\"\n",
    "print(number)\n",
    "# [\"1\", \"2\", \"3\", \"4\", \"5\"]を出力してください\n",
    "print(number.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "BJk7ch8iUxM",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 20
   },
   "source": [
    "### 1.2.6 janome (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "また、各トークン（`Token`オブジェクト）に対して、`Token.surface`で表層形を取り出すことができ、`Token.part_of_speech`で品詞を取り出すことができます。<br>\n",
    "**表層形**とは、文中において文字列として実際に出現する形式のことです。\n",
    "\n",
    "\n",
    "```python\n",
    "tokens = t.tokenize(\"pythonの本を読んだ\")\n",
    "#表層形\n",
    "for token in tokens:\n",
    "    print(token.surface)\n",
    "# 出力結果\n",
    "python \n",
    "の\n",
    "本\n",
    "を\n",
    "読ん\n",
    "だ\n",
    "```\n",
    "```python\n",
    "# 品詞\n",
    "for token in tokens:\n",
    "    print(token.part_of_speech)\n",
    "# 出力結果\n",
    "名詞,固有名詞,組織,*\n",
    "助詞,連体化,*,*\n",
    "名詞,一般,*,*\n",
    "助詞,格助詞,一般,*\n",
    "動詞,自立,*,*\n",
    "助動詞,*,*,*\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 説明文の例と<a href='https://aidemy.net/courses/5050/exercises/HkTGq3UsLgz' target='_blank'>janome(2)</a>を参考に、「豚の肉を食べた」という文から名詞と動詞を取り出して以下のようにリスト表記で出力してください。<br>\n",
    "   `[\"豚\", \"肉\", \"食べ\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"豚の肉を食べた\")\n",
    "\n",
    "# 以下のリストに答えを代入してください\n",
    "word = []\n",
    "\n",
    "# 以下に回答を作成してください\n",
    "for token in tokens:\n",
    "    part_of_speech = \n",
    "    if \n",
    "        word.append(token.surface)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- \"豚\"の形態素解析をすると品詞は`「名詞,一般,*,*」`と出力されます。そのため`.split[0]`とすることで品詞を取り出すことができます。\n",
    "- 名詞と動詞を取り出したいので、`or`を使うと綺麗に書くことができます。\n",
    "- 文字列を追加しリストを作りたい時は、`append`メソッドを用いましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"豚の肉を食べた\")\n",
    "\n",
    "# 以下のリストに答えを代入してください\n",
    "word = []\n",
    "\n",
    "# 以下に回答を作成してください\n",
    "for token in tokens:\n",
    "    part_of_speech = token.part_of_speech.split(\",\")[0]\n",
    "    if part_of_speech == \"名詞\" or part_of_speech == \"動詞\":\n",
    "        word.append(token.surface)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "H1lXc3UsIef",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.2.7 Ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "引き続き、単語分割という機械が文章の意味を理解するための方法について紹介していきます。<br>\n",
    "<b style='color: #AA0000'>Ngram</b>とは、 先ほど述べたように**N文字ごとに単語を切り分ける** 、または **N単語ごとに文章を切り分ける** 解析手法のことです。<br>\n",
    "**Ngram**のアルゴリズムは以下の`gen_Ngram`ように書くことができます。<br>\n",
    "<b style='color: #AA0000'>単語のNgram</b>を求めたい場合は、**引数に単語と切り出したい数**を入れます。<br>\n",
    "<b style='color: #AA0000'>文章のNgram</b>を求めたい場合は、**janomeの`tokenize`関数を用いて分かち書きのリストを作成し、その分かち書きのリストと切り出したい数**を引数に入れます。 <br>\n",
    "<br>\n",
    "\"pythonの本を読んだ\"、という文章を3単語ごと(N=3)に分割する場合を考えましょう。<br>\n",
    "janomeを用いると` [\"python\", \"の\", \"本\", \"を\", \"読ん\", \"だ\"]`と分割されます。連続した3単語は、6 - 3 + 1 (品詞を元に分割された数 - N + 1) = 4個取ることができます。<br>\n",
    "結果は`[\"pythonの本\", \"の本を\", \"本を読ん\", \"を読んだ\"]`となります。\n",
    "\n",
    "\n",
    "```python\n",
    "from janome.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokens = tokenizer.tokenize(\"pythonの本を読んだ\", wakati=True)\n",
    "# tokens = [\"python\", \"の\", \"本\", \"を\", \"読ん\", \"だ\"]\n",
    "\n",
    "def gen_Ngram(words,N):\n",
    "    ngram = [] # ここに切り出した単語を追加していきます。\n",
    "    for i in range(len(words)-N+1): # 連続したN個の単語が取れるまでfor文で繰り返します。\n",
    "        cw = \"\".join(words[i:i+N]) # N個分の単語をつなげてcwに代入します。\n",
    "        ngram.append(cw)\n",
    "\n",
    "    return ngram\n",
    "\n",
    "print(gen_Ngram(tokens, 2))\n",
    "print(gen_Ngram(tokens, 3))\n",
    "# 文章のトリグラムの場合\n",
    "gen_Ngram(tokens, 3)\n",
    "# 出力結果\n",
    "[\"pythonの本\", \"の本を\", \"本を読ん\", \"を読んだ\"]\n",
    "\n",
    "# 単語のバイグラムの場合\n",
    "gen_Ngram(\"bird\", 2)\n",
    "# 出力結果\n",
    "[\"bi\", \"ir\", \"rd\"]\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 「太郎はこの本を二郎を見た女性に渡した。」という文からNgram（文章のバイグラムとトリグラム）を生成し表示てください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"太郎はこの本を二郎を見た女性に渡した。\", wakati=True)\n",
    "\n",
    "def gen_Ngram(words,N):\n",
    "    # Ngramを生成してください\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return ngram\n",
    "\n",
    "print(gen_Ngram(tokens, 2))\n",
    "print(gen_Ngram(tokens, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- リストで参照できないインデックスを入力してしまうとエラーになってしまします。Ngramのアルゴリズムを参考に繰り返しの範囲に気を付けましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(\"太郎はこの本を二郎を見た女性に渡した。\", wakati=True)\n",
    "\n",
    "def gen_Ngram(words,N):\n",
    "    # Ngramを生成してください\n",
    "    ngram = []\n",
    "    for i in range(len(words)-N+1):\n",
    "        cw = \"\".join(words[i:i+N])\n",
    "        ngram.append(cw)\n",
    "\n",
    "    return ngram\n",
    "\n",
    "print(gen_Ngram(tokens, 2))\n",
    "print(gen_Ngram(tokens, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "rk6E_RQbl-f"
   },
   "source": [
    "## 1.3 正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "HkZm5nLiIgM",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.3.1 正規化 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "自然言語処理では、複数の文書から特徴を抽出する場合、入力ルールが統一されておらず表記揺れが発生している場合があります。（例 iPhoneとiphone）<br>\n",
    "同じはずの単語を別のものとして解析してしまい、意図しない解析結果がもたらされてしまいます。<br>\n",
    "全角を半角に統一や大文字を小文字に統一等、ルールベースで文字を変換することを <b style='color: #AA0000'>正規化</b>と言います。\n",
    "\n",
    "**正規化を行い過ぎると本来区別すべき内容も区別できなくなる** ため注意しましょう。\n",
    "\n",
    "**＜用語＞**\n",
    "\n",
    "> - **表記揺れ**：同じ文書の中で、同音・同義で使われるべき語句が異なって表記されていること\n",
    "> - **正規化**：表記揺れを防ぐためルールベースで文字や数字を変換すること\n",
    "\n",
    "文字列の正規化において、ライブラリの <b style='color: #AA0000'>NEologd</b>を用いると容易に正規化を行うことができます。<br>\n",
    "**`neologdn.normalize(\"正規化したい文字列\")`** と表記すると、正規化された文字列が返り値として渡されます。\n",
    "\n",
    "**`neologdn`** で行うことができる正規化は以下のものとなります。\n",
    "> - 全角英数字を半角に統一　`ａｉ -> ai`\n",
    "> - 半角カタカナを全角に統一 `ｶﾀｶﾅ -> カタカナ`\n",
    "> - 長音短縮 `ワーーーーーーーーイ -> ワーイ`\n",
    "> - 似た文字種の統一 `\"− ー - \"-> \"-\"`\n",
    "> - 不必要なスペースの削除 `\"ス　　　ペ　ース　　　\"-> \"スペース\"`　\n",
    "> - 繰り返しの制限 （問題で確認）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- `neologdn`をインポートして実行結果から正規化されていることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "# neologdnをインポートしてください\n",
    "\n",
    "\n",
    "# 半角カタカナを全角に統一\n",
    "a = neologdn.normalize(\"ｶﾀｶﾅ\")\n",
    "print(a)\n",
    "\n",
    "# 長音短縮\n",
    "b = neologdn.normalize(\"長音短縮ウェーーーーイ\")\n",
    "print(b)\n",
    "\n",
    "# 似た文字の統一\n",
    "c = neologdn.normalize(\"いろんなハイフン˗֊‐‑‒–⁃⁻₋−\")\n",
    "print(c)\n",
    "\n",
    "# 全角英数字を半角に統一 + 不要なスペースの削除\n",
    "d = neologdn.normalize(\"　　　ＤＬ　　デ  ィ ープ ラ  ーニング　　　　　\")\n",
    "print(d)\n",
    "\n",
    "# 繰り返しの制限\n",
    "e = neologdn.normalize(\"かわいいいいいいいいい\", repeat=6)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `import ライブラリ名`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "# neologdnをインポートしてください\n",
    "import neologdn\n",
    "\n",
    "# 半角カタカナを全角に統一\n",
    "a = neologdn.normalize(\"ｶﾀｶﾅ\")\n",
    "print(a)\n",
    "\n",
    "# 長音短縮\n",
    "b = neologdn.normalize(\"アイデミーーーーーーーー\")\n",
    "print(b)\n",
    "\n",
    "# 似た文字の統一\n",
    "c = neologdn.normalize(\"いろんなハイフン˗֊‐‑‒–⁃⁻₋−\")\n",
    "print(c)\n",
    "\n",
    "# 全角英数字を半角に統一 + 不要なスペースの削除\n",
    "d = neologdn.normalize(\"　　　ＤＬ　　デ  ィ ープ ラ  ーニング　　　　　\")\n",
    "print(d)\n",
    "\n",
    "# 繰り返しの制限\n",
    "e = neologdn.normalize(\"あいでみいいいいいいいいいいい\", repeat=6)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "BkfX92UsIgf",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.3.2 正規化 (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<a href='https://aidemy.net/courses/5050/exercises/HkZm5nLiIgM' target='_blank'>正規化(1)</a>では、ライブラリを用いた正規化について見てきました。<br>\n",
    "次は、自分のデータに合わせて正規化したいときのために **自分自身で正規化をするための方法** について説明します。<br>\n",
    "\n",
    "文書中に「iphone」「iPhone」の２種類の単語があった時に、これらを同一のものとして扱うために表記を統一する必要があります。<br>\n",
    "大文字を小文字に揃えたいときは、 **`.lower()`** を文字列につけることにより揃えることができます。\n",
    "\n",
    "以下の例のようにコード内で何度も用いるようなものは関数にすることが多いです。\n",
    "\n",
    "```python \n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "lower_letters = lower_text(\"iPhone\")\n",
    "print(lower_letters)\n",
    "# 出力結果\n",
    "iphone\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 説明文の例を参考に、「iPhone, IPAD, MacBook」を小文字にして出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "text = \"iPhone, IPAD, MacBook\"\n",
    "# 「iPhone, IPAD, MacBook」を小文字にして出力してください\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 関数としなくても良いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "text = \"iPhone, IPAD, MacBook\"\n",
    "# 「iPhone, IPAD, MacBook」を小文字にして出力してください\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "H1mQchIjIxz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.3.3 正規化 (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "また正規化では、数字の置き換えを行うことがあります。<br>\n",
    "数字の置き換えを行う理由としては、 **数値表現が多様で出現頻度が高い割には自然言語処理のタスクに役に立たない場合があるから** です。<br>\n",
    "たとえば、ニュース記事を「スポーツ」や「政治」のようなカテゴリに分類するタスクを考えましょう。この時、記事中には多様な数字表現が出現すると思いますが、カテゴリの分類にはほとんど役に立たないと考えられます。そのため、 **数字を別の記号に置き換えて語彙数を減らしてしまいます。**\n",
    "\n",
    "ここでは正規表現という特殊な表現方法を使って文字列を変換します。正規表現について詳しくは正規化(4)にて説明します。  \n",
    "正規表現操作にはPythonの標準ライブラリ <b style='color: #AA0000'>re</b>を使います。<br>\n",
    "文字列を別の文字列に置き換えるには、<br> **`re.sub(正規表現, 置換する文字列, 置換される文字列全体 [, 置換回数])`**<br>\n",
    "つまり、第一引数に置き換えたいものを正規表現で指定し、第二引数に置き換える文字列を示す。<br>\n",
    "第三引数に置換する文字列全体を指定します。第四引数の回数を指定しないと、全て置換されることになります。<br>\n",
    "以下の例を見てみましょう。\"昨日は6時に起きて11時に寝た。\"という文章があるとします。<br>\n",
    "`normalize_number`は文章から数字を削除する関数です。<br>\n",
    "`re.sub`の第一引数`\\d`は数字列を表す正規表現です。これを用いることで任意の数字列を指定することができます。<br>\n",
    "第二引数は`\"<NUM>\"`となっており、第一引数で指定された文字列を`<NUM>`に書き換える操作になります。<br>\n",
    "第三引数で文章を指定しており、第四引数が指定されていないので、文章中の数字列を全て変更する操作を行います。\n",
    "\n",
    "\n",
    "\n",
    "```python \n",
    "import re\n",
    "\n",
    "def normalize_number(text):\n",
    "    replaced_text = re.sub(\"\\d\", \"<NUM>\", text)\n",
    "    return replaced_text\n",
    "replaced_text = normalize_number(\"昨日は6時に起きて11時に寝た。\")\n",
    "print(replaced_text)\n",
    "# 出力結果\n",
    "昨日は<NUM>時に起きて<NUM>時に寝た。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 説明文の例を参考に`終日は前日よりも39.03ドル(0.19%)高い。`という文に対して、数字を`!`に置き換えることで、単語の正規化をおこなってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_number(text):\n",
    "    replaced_text = \n",
    "    return replaced_text\n",
    "\n",
    "replaced_text = \n",
    "print(replaced_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 文字列の置き換えは`re.sub(正規表現, 置換する文字列, 置換される文字列全体 [, 置換回数])`を利用してください。\n",
    "- `macOS`の場合、`\\`は`option` + `¥`で入力することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_number(text):\n",
    "    replaced_text = re.sub(\"\\d\", \"!\", text)\n",
    "    return replaced_text\n",
    "\n",
    "replaced_text = normalize_number(\"終日は前日よりも39.03ドル(0.19%)高い。\")\n",
    "print(replaced_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5050,
    "exerciseId": "SkVm9h8iLez",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 1.3.4 正規表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<b style='color: #AA0000'>正規表現</b>とは、文字列の集合を一つの文字や別の文字列で置き換える表現法のことです。<br>\n",
    "文字列の検索機能などで広く使われています。\n",
    "\n",
    "```\n",
    "12A3B -> \\d\\dA\\dB\n",
    "```\n",
    "上記の例では、半角数字を全て正規表現`\\d`で表しています。<br>\n",
    "正規表現(3)のように自然言語処理では、解析に必要ないと思われる文字列の集合を置き換えることによりデータ量を減らします。<br>\n",
    "正規表現はそのような文字列の集合を置換するときに用いられます。\n",
    "\n",
    "自然言語処理でよく用いられる正規表現は以下の表の通りです。\n",
    "\n",
    "|正規表現|意味|\n",
    "|:---|:---:|\n",
    "|`\\d or [0-9]`|数字|\n",
    "|`\\D or [^0-9]`|数字以外|\n",
    "|`\\s or [\\t\\n\\r\\f\\v]`|空白|\n",
    "|`\\w or [a-xA-Z0-9_]`|英数字|\n",
    "|`\\W or [\\a-zA-Z0-9_]`|英数字以外|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下の文章の空欄に入る最も適当な語句の組み合わせを選んでください。\n",
    "- 正規表現とは、「」ために「」の集合を置換します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 「見やすくする」、「文字列」\n",
    "- 「データ量を減らす」、「文字列」\n",
    "- 「データ量を減らす」、「数字」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 解析に必要ない文字列の存在のためにデータ量が非常に大きくなってしまう場合があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 「データ量を減らす」、「文字列」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 1.5 まとめ問題(提出不要)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "青空文庫のデータをもとにこころ(夏目漱石)の読み込みを行います\n",
    "(データは /5050_nlp_dataに配置されています)\n",
    "\n",
    "kokoro.txtは、shift-jisで記述されているため、注意してください。\n",
    "\n",
    "出典:<a href=\"https://www.aozora.gr.jp/\" target=\"_blank\">[青空文庫]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- kokoro.txtを読み込んでください\n",
    "- テキストには、《　》でルビ(ふりがな)が振ってあります。\n",
    "- また、各章の説明が [　] で囲まれています。\n",
    "- ここでは、簡単のため、《　》　と　[　] 本体と内部の文章を取り除けばいいものとします。\n",
    "- 読み込んだ文章の動詞をjanomeを用いて取り出し、print()を用い出力してください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "#ファイルパスは適宜変更してください\n",
    "text_data = open(\"./5050_nlp_data/kokoro.txt\",encoding = \"shift-jis\")\n",
    "text = text_data.read()\n",
    "text_data.close()\n",
    "\n",
    "#ルビと括弧を削除してください\n",
    "text = \n",
    "text = \n",
    "\n",
    "#動詞のみを出力してください\n",
    "t = Tokenizer()\n",
    "tokens = \n",
    "\n",
    "for token in tokens:\n",
    "    if(token.part_of_speech.split(\",\")[0] == \"動詞\"):\n",
    "        print(token.surface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- ルビ《　》を削除する正規表現としては、\"《[^》]+》\"があります。\n",
    "- [　]については、\"［.+?］\"を使用してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "#ファイルパスは適宜変更してください\n",
    "text_data = open(\"./5050_nlp_data/kokoro.txt\",encoding = \"shift-jis\")\n",
    "text = text_data.read()\n",
    "text_data.close()\n",
    "\n",
    "#ルビと括弧を削除してください\n",
    "text = re.sub(u\"《[^》]+》\", \"\", text)\n",
    "text = re.sub(u\"［.+?］\", \"\", text)\n",
    "\n",
    "#動詞のみを出力してください\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(text)\n",
    "\n",
    "for token in tokens:\n",
    "    if(token.part_of_speech.split(\",\")[0] == \"動詞\"):\n",
    "        print(token.surface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "品詞は、`token.part_of_speech`で取り出すことができます。\n",
    "\n",
    "品詞は`「名詞,一般,*,*」`と出力されます。そのため`.split[0]`とすることで品詞を取り出すことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
